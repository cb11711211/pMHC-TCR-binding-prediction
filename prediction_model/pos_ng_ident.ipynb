{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuxinchao/.conda/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tqdm\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_seqCDR(seqCDR):\n",
    "    encoding_list = []\n",
    "    for i in range(len(seqCDR)):\n",
    "        if seqCDR[i] == \"*\":\n",
    "            encoding_list.append(np.zeros(5).reshape(1,5))\n",
    "        else:\n",
    "            encoding_list.append(af.loc[seqCDR[i]].values.reshape(1,5))\n",
    "    return np.array(encoding_list).reshape(1,-1)\n",
    "\n",
    "af = pd.read_csv(\"~/data/project/pMHC-TCR/library/Atchley_factors.csv\")\n",
    "af.index = af[\"Amino acid\"]\n",
    "af.drop(columns=[\"Amino acid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset 230220.csv\n",
    "class TCRDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_ng = df.copy()\n",
    "        df_ng = df_ng[df_ng[\"HLA\"] != \"-\"]\n",
    "        df_ng[\"Class\"] = \"negative\"\n",
    "        df_ng[\"AseqCDR_3\"] = df_ng[\"AseqCDR_3\"].apply(\n",
    "            lambda x: random.choice(list(set(df[\"AseqCDR_3\"]) - set(x))))\n",
    "        df_ng[\"BseqCDR_3\"] = df_ng[\"BseqCDR_3\"].apply(\n",
    "            lambda x: random.choice(list(set(df[\"BseqCDR_3\"]) - set(x))))\n",
    "        df_pos = df[df[\"Class\"] == \"positive\"]\n",
    "        df = pd.concat([df_pos, df_ng], axis=0)\n",
    "        df = df[\"HLA\", \"Neo\", \"AseqCDR_3\", \"BseqCDR_3\", \"Class\"]\n",
    "        seq_list = [\"AseqCDR_3\", \"BseqCDR_3\"]\n",
    "        len_map = df[seq_list].applymap(len).max()\n",
    "        X_feature = np.zeros((len(df), 0))\n",
    "        for column in seq_list:\n",
    "            df[column] = df[column].str.ljust(len_map[column], \"*\")\n",
    "            encode_seq_result = list()\n",
    "            for i in df[column]:\n",
    "                encode_seq_result.append(encode_seqCDR(i))\n",
    "            col_name = column + \"_encode\"\n",
    "            df[col_name] = encode_seq_result\n",
    "            col_feature = np.zeros((0, len_map[column]*5))\n",
    "            for i in range(len(df)):\n",
    "                col_feature = np.vstack((col_feature, df.loc[i, col_name].reshape(1, -1)))\n",
    "            X_feature = np.hstack((X_feature, col_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more complicated dataset which the HLA has more than 14 types\n",
    "class HLAAutoEncoder_twoLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(HLAAutoEncoder_twoLayer, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim*4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_dim*4, hidden_dim*2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim*2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_dim*2, hidden_dim*4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_dim*4, input_dim),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HLAAutoEncoder_twoLayer(input_dim=5*len(df[\"aaSeqHLA\"].unique().max()), hidden_dim=10)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "output = []\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    for idx, (data) in enumerate(train_loader):\n",
    "        data = Variable(data).float()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 230221 dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_451163/2328245337.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_a[\"AseqCDR\"] = df_a[\"aaSeqCDR\"]\n",
      "/tmp/ipykernel_451163/2328245337.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_a.drop(columns=[\"aaSeqCDR\",\"aaSeqCDR1\",\"aaSeqCDR2\",\"aaSeqCDR3\"], inplace=True)\n",
      "/tmp/ipykernel_451163/2328245337.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_b[\"BseqCDR\"] = df_b[\"aaSeqCDR\"]\n",
      "/tmp/ipykernel_451163/2328245337.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_b.drop(columns=[\"aaSeqCDR\",\"aaSeqCDR1\",\"aaSeqCDR2\",\"aaSeqCDR3\"], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SSCMGGMNQR     494\n",
       "VVGAVGVGK      373\n",
       "VVVGAGDVGK     143\n",
       "ATAPSLSGK      118\n",
       "VVVGADGVGK      99\n",
       "SVCAGILSY       79\n",
       "VLLSHLSYL       77\n",
       "ATATAPSLSGK     76\n",
       "TTAPPLSGK       64\n",
       "VVGAGDVGK       42\n",
       "SLMEQIPHL       18\n",
       "LVTDDLLTL       14\n",
       "SLLMWITQC        9\n",
       "ELAGIGILTV       8\n",
       "FLSEQLSIKL       6\n",
       "GVLEVSHSI        6\n",
       "AAGIGILTV        2\n",
       "GILGFVFTL        2\n",
       "NLVPMVATV        2\n",
       "GTSGSPIVNR       1\n",
       "LLFGYAVYV        1\n",
       "ELAGIGALTV       1\n",
       "ELAAIGILTV       1\n",
       "LLFGYPVAV        1\n",
       "YLEPGPVTV        1\n",
       "SLYNTIATL        1\n",
       "EAAGIGILTV       1\n",
       "SLFNTIAVL        1\n",
       "GILEFVFTL        1\n",
       "SLLMWITQV        1\n",
       "ALWGFFPVL        1\n",
       "LLFGYPVYV        1\n",
       "SLYNTVATL        1\n",
       "Name: NeoAA, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"/DATA/User/wuxinchao/project/data/seqData/pMHC-TCR_20230221_Info.xlsx\")\n",
    "# select the HLA:HLA-A*02:01, HLA-A*11:01\n",
    "df = df[(df[\"HLA\"] == \"HLA-A*02:01\") | (df[\"HLA\"] == \"HLA-A*11:01\")]\n",
    "# set the index of cellname and chain\n",
    "df = df.set_index(['cellname', \"chain\"])\n",
    "# extract the NeoAA, HLA, and aaSeqCDR columns\n",
    "df = df[[\"NeoAA\", \"HLA\", \"aaSeqCDR1\", \"aaSeqCDR2\", \"aaSeqCDR3\", \"Class\"]]\n",
    "df[\"aaSeqCDR\"] = df[df.columns[2:-1]].apply(\n",
    "    # lambda x: x[0] + 'X' * (7 - len(x[0])) + x[1] + x[2],\n",
    "    lambda x: '_'.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "df_a = df.loc[idx[:,\"TRA\"],]\n",
    "df_a[\"AseqCDR\"] = df_a[\"aaSeqCDR\"]\n",
    "df_a.drop(columns=[\"aaSeqCDR\",\"aaSeqCDR1\",\"aaSeqCDR2\",\"aaSeqCDR3\"], inplace=True)\n",
    "# drop the chain index\n",
    "df_a.index = df_a.index.droplevel(1)\n",
    "# print(df_a)\n",
    "df_b = df.loc[idx[:,\"TRB\"],]\n",
    "df_b[\"BseqCDR\"] = df_b[\"aaSeqCDR\"]\n",
    "df_b.drop(columns=[\"aaSeqCDR\",\"aaSeqCDR1\",\"aaSeqCDR2\",\"aaSeqCDR3\"], inplace=True)\n",
    "# drop the chain index\n",
    "df_b.index = df_b.index.droplevel(1)\n",
    "# print(df_b)\n",
    "\n",
    "# merge the TRA and TRB dataframes by cellname, HLAs, and NeoAA\n",
    "df_ab = pd.merge(df_a, df_b, on=[\"cellname\", \"HLA\", \"NeoAA\", \"Class\"])\n",
    "\n",
    "df = df_ab\n",
    "# select the NeoAA first 3 aa and last 3 aa as new column\n",
    "df[\"Neo_first3\"] = df[\"NeoAA\"].str[:3]\n",
    "df[\"Neo_last3\"] = df[\"NeoAA\"].str[-3:]\n",
    "df = df.drop(columns=[\"NeoAA\"])\n",
    "# df[\"NeoAA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSC_MNQ    494\n",
       "VVG_GVG    373\n",
       "ATA_LSG    194\n",
       "VVV_DVG    143\n",
       "VVV_GVG     99\n",
       "SVC_ILS     79\n",
       "VLL_LSY     77\n",
       "TTA_LSG     64\n",
       "VVG_DVG     42\n",
       "SLM_IPH     18\n",
       "LVT_LLT     14\n",
       "SLL_ITQ     10\n",
       "ELA_ILT      9\n",
       "GVL_SHS      6\n",
       "FLS_SIK      6\n",
       "GIL_VFT      3\n",
       "AAG_ILT      2\n",
       "NLV_VAT      2\n",
       "YLE_PVT      1\n",
       "LLF_PVY      1\n",
       "SLF_IAV      1\n",
       "SLY_VAT      1\n",
       "SLY_IAT      1\n",
       "GTS_IVN      1\n",
       "LLF_PVA      1\n",
       "ELA_ALT      1\n",
       "LLF_AVY      1\n",
       "ALW_FPV      1\n",
       "EAA_ILT      1\n",
       "Name: Neo, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine whether to use Neo column, and the decision is not to use\n",
    "# Instead, we use encoding of NeoAA\n",
    "df[\"Neo\"] = df[\"NeoAA\"].str.slice(0,3) + \"_\" + df[\"NeoAA\"].str.slice(-4,-1)\n",
    "df.drop(columns=[\"NeoAA\"], inplace=True)\n",
    "df[\"Neo\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HLA-A*11:01    1489\n",
       "HLA-A*02:01     157\n",
       "Name: HLA, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"HLA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    1109\n",
       "negative     537\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the final output dataframe that we need to use\n",
    "# df = df.drop(columns=[\"Neo\"])\n",
    "df.to_csv(\"~/data/project/data/seqData/230221.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCRDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        # super(TCRDataset, self).__init__()\n",
    "        df = pd.read_csv(file_path, index_col=0)\n",
    "        # get the CDR3 region\n",
    "        for chain in [\"AseqCDR\", \"BseqCDR\"]:\n",
    "            # df[chain+\"_1\"] = df[chain].str.split(\"_\").str[0]\n",
    "            # df[chain+\"_2\"] = df[chain].str.split(\"_\").str[1]\n",
    "            df[chain+\"_3\"] = df[chain].str.split(\"_\").str[2]\n",
    "            df.drop(columns=[chain], inplace=True)\n",
    "        df_ps = df[df[\"Class\"] == \"positive\"]\n",
    "        df_ng_ex = df[df[\"Class\"] == \"negative\"]\n",
    "        df_ng_em = df.copy()\n",
    "        df_ng_em = df_ng_em[df_ng_em[\"Class\"] == \"positive\"]\n",
    "        df_ng_em[\"AseqCDR_3\"] = df_ng_em[\"AseqCDR_3\"].apply(lambda x: random.choice(list(set(df_ng_em[\"AseqCDR_3\"]) - set(x))))\n",
    "        df_ng_em[\"BseqCDR_3\"] = df_ng_em[\"BseqCDR_3\"].apply(lambda x: random.choice(list(set(df_ng_em[\"BseqCDR_3\"]) - set(x))))\n",
    "        df_ng = pd.concat([df_ng_em, df_ng_ex], axis=0)\n",
    "        df_ng.index = range(len(df_ng))\n",
    "        df = pd.concat([df_ps, df_ng], axis=0)\n",
    "        # encode the Neo_first3, Neo_last3\n",
    "        for seq in [\"Neo_first3\", \"Neo_last3\"]:\n",
    "            df[seq] = df[seq].apply(lambda x: encode_seqCDR(x))\n",
    "        # encode the CDR3 region\n",
    "        len_map = {\n",
    "            \"AseqCDR_3\": df[\"AseqCDR_3\"].apply(lambda x: len(x)).max(),\n",
    "            \"BseqCDR_3\": df[\"BseqCDR_3\"].apply(lambda x: len(x)).max(),\n",
    "        }\n",
    "        for chain in [\"AseqCDR_3\", \"BseqCDR_3\"]:\n",
    "            length = len_map[chain]\n",
    "            df[chain] = df[chain].apply(lambda x: x + \"*\" * (length - len(x)))\n",
    "            df[chain] = df[chain].apply(lambda x: encode_seqCDR(x))\n",
    "\n",
    "        # encode HLA type through one-hot encoding\n",
    "        X_HLA = df[\"HLA\"].values.reshape(-1, 1)\n",
    "        HLAencoder = OneHotEncoder()\n",
    "        X_HLA_encoded = HLAencoder.fit_transform(X_HLA).toarray()\n",
    "\n",
    "        X_features = torch.zeros((len(df),0))\n",
    "        for seq in [\"Neo_first3\", \"Neo_last3\", \"AseqCDR_3\", \"BseqCDR_3\"]:\n",
    "            # X_features = df[seq]\n",
    "            # print(df[seq].values.shape)\n",
    "            # convert the df[seq] into torch tensor\n",
    "            X_features = torch.cat((X_features, \n",
    "            torch.from_numpy(np.vstack(df[seq].values))), dim=1)\n",
    "        \n",
    "        X = torch.cat((torch.from_numpy(X_HLA_encoded), X_features), dim=1)\n",
    "        # encode the class label\n",
    "        y = df[\"Class\"].apply(lambda x: 1 if x == \"positive\" else 0).values\n",
    "\n",
    "        self.X = X\n",
    "        self.y = torch.from_numpy(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for test\n",
    "file_path = \"~/data/project/data/seqData/230221.csv\"\n",
    "df = pd.read_csv(file_path, index_col=0)\n",
    "# get the CDR3 region\n",
    "for chain in [\"AseqCDR\", \"BseqCDR\"]:\n",
    "    # df[chain+\"_1\"] = df[chain].str.split(\"_\").str[0]\n",
    "    # df[chain+\"_2\"] = df[chain].str.split(\"_\").str[1]\n",
    "    df[chain+\"_3\"] = df[chain].str.split(\"_\").str[2]\n",
    "    df.drop(columns=[chain], inplace=True)\n",
    "# delete the index\n",
    "df_ps = df[df[\"Class\"] == \"positive\"]\n",
    "df_ng_ex = df[df[\"Class\"] == \"negative\"]\n",
    "df_ng_em = df.copy()\n",
    "df_ng_em = df_ng_em[df_ng_em[\"Class\"] == \"positive\"]\n",
    "df_ng_em[\"AseqCDR_3\"] = df_ng_em[\"AseqCDR_3\"].apply(lambda x: random.choice(list(set(df_ng_em[\"AseqCDR_3\"]) - set(x))))\n",
    "df_ng_em[\"BseqCDR_3\"] = df_ng_em[\"BseqCDR_3\"].apply(lambda x: random.choice(list(set(df_ng_em[\"BseqCDR_3\"]) - set(x))))\n",
    "df_ng = pd.concat([df_ng_em, df_ng_ex], axis=0)\n",
    "df_ng.index = range(len(df_ng))\n",
    "df = pd.concat([df_ps, df_ng], axis=0)\n",
    "# encode the Neo_first3, Neo_last3\n",
    "for seq in [\"Neo_first3\", \"Neo_last3\"]:\n",
    "    df[seq] = df[seq].apply(lambda x: encode_seqCDR(x))\n",
    "# encode the CDR3 region\n",
    "len_map = {\n",
    "    \"AseqCDR_3\": df[\"AseqCDR_3\"].apply(lambda x: len(x)).max(),\n",
    "    \"BseqCDR_3\": df[\"BseqCDR_3\"].apply(lambda x: len(x)).max(),\n",
    "}\n",
    "for chain in [\"AseqCDR_3\", \"BseqCDR_3\"]:\n",
    "    length = len_map[chain]\n",
    "    # print(length)\n",
    "    df[chain] = df[chain].apply(lambda x: x + \"*\" * (length - len(x)))\n",
    "    df[chain] = df[chain].apply(lambda x: encode_seqCDR(x).reshape(1, -1))\n",
    "\n",
    "# encode HLA type through one-hot encoding\n",
    "X_HLA = df[\"HLA\"].values.reshape(-1, 1)\n",
    "HLAencoder = OneHotEncoder()\n",
    "X_HLA_encoded = HLAencoder.fit_transform(X_HLA).toarray()\n",
    "\n",
    "X_features = torch.zeros((len(df),0))\n",
    "for seq in [\"Neo_first3\", \"Neo_last3\", \"AseqCDR_3\", \"BseqCDR_3\"]:\n",
    "    # X_features = df[seq]\n",
    "    # print(df[seq].values.shape)\n",
    "    # convert the df[seq] into torch tensor\n",
    "    X_features = torch.cat((X_features, \n",
    "        torch.from_numpy(np.vstack(df[seq].values))), dim=1)\n",
    "\n",
    "# put the features together including encoded HLA type, Neo_first3, Neo_last3, and CDR3 region\n",
    "X = torch.cat((torch.from_numpy(X_HLA_encoded), X_features), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2755, 237])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # 237 = 20*5 + 21*5 + 6*5 + 2 \n",
    "# len_map # A: 20, B: 21\n",
    "# X_HLA_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the object data into torch tensor\n",
    "# np.hstack([X_HLA_encoded, df[[\"Neo_first3\", \"Neo_last3\", \"AseqCDR_3\", \"BseqCDR_3\"]]]).shape\n",
    "X_features = torch.zeros((len(df),0))\n",
    "for seq in [\"Neo_first3\", \"Neo_last3\", \"AseqCDR_3\", \"BseqCDR_3\"]:\n",
    "    # X_features = df[seq]\n",
    "    # print(df[seq].values.shape)\n",
    "    # convert the df[seq] into torch tensor\n",
    "    X_features = torch.cat((X_features, torch.from_numpy(np.vstack(df[seq].values))), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2755, 235])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[\"Neo_first3\"].values\n",
    "X_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"~/data/project/data/seqData/230221.csv\"\n",
    "TCRData = TCRDataset(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pMHC_TCR_model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 hidden_size=5, \n",
    "                 batch_size=32, \n",
    "                 num_layers=2, \n",
    "                 device=\"cpu\", \n",
    "                 use_whole_data=False) -> None:\n",
    "        super(pMHC_TCR_model, self).__init__()\n",
    "        if use_whole_data:\n",
    "            self.batch_size = 0\n",
    "        else:\n",
    "            self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        self.label = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.batch_size == 0:\n",
    "            self.batch_size = input.shape[0]\n",
    "            x = input.float()\n",
    "            h_0 = Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(self.device))\n",
    "            c_0 = Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(self.device))\n",
    "            output, (h_n, c_n) = self.lstm(x, (h_0, c_0))\n",
    "            pred = self.label(output[-1])\n",
    "        else:\n",
    "            x = input.view(-1, self.batch_size, self.input_size).float()\n",
    "            h_0 = Variable(torch.zeros(self.num_layers * 1, self.batch_size, self.hidden_size).to(self.device))\n",
    "            c_0 = Variable(torch.zeros(self.num_layers * 1, self.batch_size, self.hidden_size).to(self.device))\n",
    "            output, (hn, cn) = self.lstm(x, (h_0, c_0))\n",
    "            pred = self.label(output[-1])\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fold, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        print(output.shape, target.shape)\n",
    "        output = output.to(torch.float32)\n",
    "        target = target.to(torch.int64).view(-1, 1)\n",
    "        loss = nn.CrossEntropyLoss()(output, target)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Fold/Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                fold, epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    return train_loss\n",
    "\n",
    "def test(fold, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data).to(torch.float32)\n",
    "            target = target.to(torch.float32).view(-1, 1)\n",
    "            test_loss += nn.CrossEntropyLoss()(output, target)\n",
    "            print(test_loss)\n",
    "            pred = output.sigmoid().round()\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"Test set for fold{fold}: Average Loss: \\\n",
    "          {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} \\\n",
    "          ({100. * correct / len(test_loader.dataset):.0f}%)\")\n",
    "    return test_loss, correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for training\n",
      "-------------------Fold 0-------------------\n",
      "torch.Size([20, 1]) torch.Size([20])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected floating point type for target with class probabilities, got Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [114], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m accuracy_history \u001b[39m=\u001b[39m []\n\u001b[1;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m---> 45\u001b[0m     train_losses \u001b[39m=\u001b[39m train(fold, model, device, train_loader, optimizer, epoch)\n\u001b[1;32m     46\u001b[0m     test_losses, correct \u001b[39m=\u001b[39m test(fold, model, device, test_loader)\n\u001b[1;32m     47\u001b[0m     train_losses_history\u001b[39m.\u001b[39mappend(train_losses)\n",
      "Cell \u001b[0;32mIn [113], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(fold, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     10\u001b[0m target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mint64)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mCrossEntropyLoss()(output, target)\n\u001b[1;32m     12\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     13\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Long"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 20\n",
    "seq_length = 6\n",
    "folds = 5\n",
    "repeats = 12\n",
    "epochs = 100\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using {device} for training\")\n",
    "\n",
    "def reset_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "model = pMHC_TCR_model(input_size=237, hidden_size=5, batch_size=batch_size, num_layers=2, device=device, use_whole_data=False).to(device)\n",
    "kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "weights = torch.FloatTensor([5,6])\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].set_title(\"loss\")\n",
    "ax[1].set_title(\"accuracy\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(TCRData.X, TCRData.y)):\n",
    "    print(f\"-------------------Fold {fold}-------------------\")\n",
    "    if batch_size == 1:\n",
    "    # using the subsampler to get the data\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "        train_dataset = torch.utils.data.Subset(TCRData, train_idx)\n",
    "        test_dataset = torch.utils.data.Subset(TCRData, test_idx)\n",
    "        train_loader = torch.utils.data.DataLoader(TCRData, batch_size=len(train_dataset), sampler=train_subsampler)\n",
    "        test_loader = torch.utils.data.DataLoader(TCRData, batch_size=len(test_dataset), sampler=test_subsampler)\n",
    "    else:\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "        train_loader = torch.utils.data.DataLoader(TCRData, batch_size=batch_size, sampler=train_subsampler)\n",
    "        test_loader = torch.utils.data.DataLoader(TCRData, batch_size=batch_size, sampler=test_subsampler)\n",
    "        \n",
    "    model.apply(reset_weights)\n",
    "    train_losses_history = []\n",
    "    test_losses_history = []\n",
    "    accuracy_history = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_losses = train(fold, model, device, train_loader, optimizer, epoch)\n",
    "        test_losses, correct = test(fold, model, device, test_loader)\n",
    "        train_losses_history.append(train_losses)\n",
    "        test_losses_history.append(test_losses)\n",
    "        accuracy_history.append(correct)\n",
    "    ax[0].plot(train_losses_history, \"r*--\" ,label=f\"train loss fold{fold}\")\n",
    "    ax[0].plot(test_losses_history, \"bs.\", label=f\"test loss fold{fold}\")\n",
    "    ax[1].plot(accuracy_history, \"g^--\", label=f\"accuracy fold{fold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful functions and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the sequence are similar, (the length of the sequence are different less than 5 aa) into a batch, and then use the autoencoder to encode the HLA sequence.\n",
    "\n",
    "class LenMatchBatchSampler(data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "        buckets = [[] for i in range(300)]\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            count_zeros = int(torch.sum(self.sampler.data_source[idx] == 0) / 5)\n",
    "            buckets[count_zeros].append(idx)\n",
    "\n",
    "            if len(buckets[count_zeros]) == self.batch_size:\n",
    "                batch = list(buckets[count_zeros])\n",
    "                yield batch\n",
    "                buckets[count_zeros] = []\n",
    "\n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yield batch\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not use\n",
    "# random_seq_len = [random.randint(i) for i in range(5)]\n",
    "test_input = torch.empty(0)\n",
    "for i in range(5):\n",
    "    random_seq_len = random.randint(0, 300)\n",
    "    input = torch.randint(5, 100, (1, random_seq_len))\n",
    "    test_input = torch.cat((test_input, input), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # not use\n",
    "# # My may need to find a proper way to encode the HLA aa sequence, because there are 10 to 20 different HLA types and some of them have variants which are just one single aa difference.\n",
    "# hla_list = list(set(df[\"HLA\"]))\n",
    "# hla_list.sort()\n",
    "# hla_dict = dict()\n",
    "# for i in range(len(hla_list)):\n",
    "#     hla_dict[hla_list[i]] = i\n",
    "# # The encoding could apply autoencoder to encode the HLA sequence.\n",
    "# df[\"HLA_encode\"] = df[\"HLA\"].map(hla_dict)\n",
    "# X_feature = np.hstack((X_feature, df[\"HLA_encode\"].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 415])\n"
     ]
    }
   ],
   "source": [
    "# torch.randint(0, 10, (3, 5))\n",
    "# torch.randperm(10)\n",
    "random_seq_len = random.randint(0, 300)\n",
    "input = torch.randint(0, 100, (1, 5*random_seq_len))\n",
    "print(input.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9a3d897ef0b1e7415fe4468808571913e41281b79a56511723d411ccb064e7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
