{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuxinchao/.conda/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tqdm\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_seqCDR(seqCDR):\n",
    "    encoding_list = []\n",
    "    for i in range(len(seqCDR)):\n",
    "        if seqCDR[i] == \"*\":\n",
    "            encoding_list.append(np.zeros(5).reshape(1,5))\n",
    "        else:\n",
    "            encoding_list.append(af.loc[seqCDR[i]].values.reshape(1,5))\n",
    "    return np.array(encoding_list).reshape(1,-1)\n",
    "\n",
    "af = pd.read_csv(\"~/data/project/pMHC-TCR/library/Atchley_factors.csv\")\n",
    "af.index = af[\"Amino acid\"]\n",
    "af.drop(columns=[\"Amino acid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset 230220.csv\n",
    "class TCRDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df_ng = df.copy()\n",
    "        df_ng = df_ng[df_ng[\"HLA\"] != \"-\"]\n",
    "        df_ng[\"Class\"] = \"negative\"\n",
    "        df_ng[\"AseqCDR_3\"] = df_ng[\"AseqCDR_3\"].apply(\n",
    "            lambda x: random.choice(list(set(df[\"AseqCDR_3\"]) - set(x))))\n",
    "        df_ng[\"BseqCDR_3\"] = df_ng[\"BseqCDR_3\"].apply(\n",
    "            lambda x: random.choice(list(set(df[\"BseqCDR_3\"]) - set(x))))\n",
    "        df_pos = df[df[\"Class\"] == \"positive\"]\n",
    "        df = pd.concat([df_pos, df_ng], axis=0)\n",
    "        df = df[\"HLA\", \"Neo\", \"AseqCDR_3\", \"BseqCDR_3\", \"Class\"]\n",
    "        seq_list = [\"AseqCDR_3\", \"BseqCDR_3\"]\n",
    "        len_map = df[seq_list].applymap(len).max()\n",
    "        X_feature = np.zeros((len(df), 0))\n",
    "        for column in seq_list:\n",
    "            df[column] = df[column].str.ljust(len_map[column], \"*\")\n",
    "            encode_seq_result = list()\n",
    "            for i in df[column]:\n",
    "                encode_seq_result.append(encode_seqCDR(i))\n",
    "            col_name = column + \"_encode\"\n",
    "            df[col_name] = encode_seq_result\n",
    "            col_feature = np.zeros((0, len_map[column]*5))\n",
    "            for i in range(len(df)):\n",
    "                col_feature = np.vstack((col_feature, df.loc[i, col_name].reshape(1, -1)))\n",
    "            X_feature = np.hstack((X_feature, col_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more complicated dataset which the HLA has more than 14 types\n",
    "class HLAAutoEncoder_twoLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(HLAAutoEncoder_twoLayer, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim*4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_dim*4, hidden_dim*2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim*2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_dim*2, hidden_dim*4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_dim*4, input_dim),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HLAAutoEncoder_twoLayer(input_dim=5*len(df[\"aaSeqHLA\"].unique().max()), hidden_dim=10)\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "output = []\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    for idx, (data) in enumerate(train_loader):\n",
    "        data = Variable(data).float()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 230221 dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_451163/2328245337.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_a[\"AseqCDR\"] = df_a[\"aaSeqCDR\"]\n",
      "/tmp/ipykernel_451163/2328245337.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_a.drop(columns=[\"aaSeqCDR\",\"aaSeqCDR1\",\"aaSeqCDR2\",\"aaSeqCDR3\"], inplace=True)\n",
      "/tmp/ipykernel_451163/2328245337.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_b[\"BseqCDR\"] = df_b[\"aaSeqCDR\"]\n",
      "/tmp/ipykernel_451163/2328245337.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_b.drop(columns=[\"aaSeqCDR\",\"aaSeqCDR1\",\"aaSeqCDR2\",\"aaSeqCDR3\"], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SSCMGGMNQR     494\n",
       "VVGAVGVGK      373\n",
       "VVVGAGDVGK     143\n",
       "ATAPSLSGK      118\n",
       "VVVGADGVGK      99\n",
       "SVCAGILSY       79\n",
       "VLLSHLSYL       77\n",
       "ATATAPSLSGK     76\n",
       "TTAPPLSGK       64\n",
       "VVGAGDVGK       42\n",
       "SLMEQIPHL       18\n",
       "LVTDDLLTL       14\n",
       "SLLMWITQC        9\n",
       "ELAGIGILTV       8\n",
       "FLSEQLSIKL       6\n",
       "GVLEVSHSI        6\n",
       "AAGIGILTV        2\n",
       "GILGFVFTL        2\n",
       "NLVPMVATV        2\n",
       "GTSGSPIVNR       1\n",
       "LLFGYAVYV        1\n",
       "ELAGIGALTV       1\n",
       "ELAAIGILTV       1\n",
       "LLFGYPVAV        1\n",
       "YLEPGPVTV        1\n",
       "SLYNTIATL        1\n",
       "EAAGIGILTV       1\n",
       "SLFNTIAVL        1\n",
       "GILEFVFTL        1\n",
       "SLLMWITQV        1\n",
       "ALWGFFPVL        1\n",
       "LLFGYPVYV        1\n",
       "SLYNTVATL        1\n",
       "Name: NeoAA, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"/DATA/User/wuxinchao/project/data/seqData/pMHC-TCR_20230221_Info.xlsx\")\n",
    "# select the HLA:HLA-A*02:01, HLA-A*11:01\n",
    "df = df[(df[\"HLA\"] == \"HLA-A*02:01\") | (df[\"HLA\"] == \"HLA-A*11:01\")]\n",
    "# set the index of cellname and chain\n",
    "df = df.set_index(['cellname', \"chain\"])\n",
    "# extract the NeoAA, HLA, and aaSeqCDR columns\n",
    "df = df[[\"NeoAA\", \"HLA\", \"aaSeqCDR1\", \"aaSeqCDR2\", \"aaSeqCDR3\", \"Class\"]]\n",
    "df[\"aaSeqCDR\"] = df[df.columns[2:-1]].apply(\n",
    "    # lambda x: x[0] + 'X' * (7 - len(x[0])) + x[1] + x[2],\n",
    "    lambda x: '_'.join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "df_a = df.loc[idx[:,\"TRA\"],]\n",
    "df_a[\"AseqCDR\"] = df_a[\"aaSeqCDR\"]\n",
    "df_a.drop(columns=[\"aaSeqCDR\",\"aaSeqCDR1\",\"aaSeqCDR2\",\"aaSeqCDR3\"], inplace=True)\n",
    "# drop the chain index\n",
    "df_a.index = df_a.index.droplevel(1)\n",
    "# print(df_a)\n",
    "df_b = df.loc[idx[:,\"TRB\"],]\n",
    "df_b[\"BseqCDR\"] = df_b[\"aaSeqCDR\"]\n",
    "df_b.drop(columns=[\"aaSeqCDR\",\"aaSeqCDR1\",\"aaSeqCDR2\",\"aaSeqCDR3\"], inplace=True)\n",
    "# drop the chain index\n",
    "df_b.index = df_b.index.droplevel(1)\n",
    "# print(df_b)\n",
    "\n",
    "# merge the TRA and TRB dataframes by cellname, HLAs, and NeoAA\n",
    "df_ab = pd.merge(df_a, df_b, on=[\"cellname\", \"HLA\", \"NeoAA\", \"Class\"])\n",
    "\n",
    "df = df_ab\n",
    "# select the NeoAA first 3 aa and last 3 aa as new column\n",
    "df[\"Neo_first3\"] = df[\"NeoAA\"].str[:3]\n",
    "df[\"Neo_last3\"] = df[\"NeoAA\"].str[-3:]\n",
    "df = df.drop(columns=[\"NeoAA\"])\n",
    "# df[\"NeoAA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSC_MNQ    494\n",
       "VVG_GVG    373\n",
       "ATA_LSG    194\n",
       "VVV_DVG    143\n",
       "VVV_GVG     99\n",
       "SVC_ILS     79\n",
       "VLL_LSY     77\n",
       "TTA_LSG     64\n",
       "VVG_DVG     42\n",
       "SLM_IPH     18\n",
       "LVT_LLT     14\n",
       "SLL_ITQ     10\n",
       "ELA_ILT      9\n",
       "GVL_SHS      6\n",
       "FLS_SIK      6\n",
       "GIL_VFT      3\n",
       "AAG_ILT      2\n",
       "NLV_VAT      2\n",
       "YLE_PVT      1\n",
       "LLF_PVY      1\n",
       "SLF_IAV      1\n",
       "SLY_VAT      1\n",
       "SLY_IAT      1\n",
       "GTS_IVN      1\n",
       "LLF_PVA      1\n",
       "ELA_ALT      1\n",
       "LLF_AVY      1\n",
       "ALW_FPV      1\n",
       "EAA_ILT      1\n",
       "Name: Neo, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine whether to use Neo column, and the decision is not to use\n",
    "# Instead, we use encoding of NeoAA\n",
    "df[\"Neo\"] = df[\"NeoAA\"].str.slice(0,3) + \"_\" + df[\"NeoAA\"].str.slice(-4,-1)\n",
    "df.drop(columns=[\"NeoAA\"], inplace=True)\n",
    "df[\"Neo\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HLA-A*11:01    1489\n",
       "HLA-A*02:01     157\n",
       "Name: HLA, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"HLA\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    1109\n",
       "negative     537\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the final output dataframe that we need to use\n",
    "# df = df.drop(columns=[\"Neo\"])\n",
    "df.to_csv(\"~/data/project/data/seqData/230221.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCRDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        # super(TCRDataset, self).__init__()\n",
    "        df = pd.read_csv(file_path, index_col=0)\n",
    "        # get the CDR3 region\n",
    "        for chain in [\"AseqCDR\", \"BseqCDR\"]:\n",
    "            # df[chain+\"_1\"] = df[chain].str.split(\"_\").str[0]\n",
    "            # df[chain+\"_2\"] = df[chain].str.split(\"_\").str[1]\n",
    "            df[chain+\"_3\"] = df[chain].str.split(\"_\").str[2]\n",
    "            df.drop(columns=[chain], inplace=True)\n",
    "        df_ps = df[df[\"Class\"] == \"positive\"]\n",
    "        df_ng_ex = df[df[\"Class\"] == \"negative\"]\n",
    "        df_ng_em = df.copy()\n",
    "        df_ng_em = df_ng_em[df_ng_em[\"Class\"] == \"positive\"]\n",
    "        df_ng_em[\"AseqCDR_3\"] = df_ng_em[\"AseqCDR_3\"].apply(lambda x: random.choice(list(set(df_ng_em[\"AseqCDR_3\"]) - set(x))))\n",
    "        df_ng_em[\"BseqCDR_3\"] = df_ng_em[\"BseqCDR_3\"].apply(lambda x: random.choice(list(set(df_ng_em[\"BseqCDR_3\"]) - set(x))))\n",
    "        df_ng = pd.concat([df_ng_em, df_ng_ex], axis=0)\n",
    "        df_ng.index = range(len(df_ng))\n",
    "        df = pd.concat([df_ps, df_ng], axis=0)\n",
    "        # encode the Neo_first3, Neo_last3\n",
    "        for seq in [\"Neo_first3\", \"Neo_last3\"]:\n",
    "            df[seq] = df[seq].apply(lambda x: encode_seqCDR(x))\n",
    "        # encode the CDR3 region\n",
    "        len_map = {\n",
    "            \"AseqCDR_3\": df[\"AseqCDR_3\"].apply(lambda x: len(x)).max(),\n",
    "            \"BseqCDR_3\": df[\"BseqCDR_3\"].apply(lambda x: len(x)).max(),\n",
    "        }\n",
    "        for chain in [\"AseqCDR_3\", \"BseqCDR_3\"]:\n",
    "            length = len_map[chain]\n",
    "            df[chain] = df[chain].apply(lambda x: x + \"*\" * (length - len(x)))\n",
    "            df[chain] = df[chain].apply(lambda x: encode_seqCDR(x))\n",
    "\n",
    "        # encode HLA type through one-hot encoding\n",
    "        X_HLA = df[\"HLA\"].values.reshape(-1, 1)\n",
    "        HLAencoder = OneHotEncoder()\n",
    "        X_HLA_encoded = HLAencoder.fit_transform(X_HLA).toarray()\n",
    "\n",
    "        X_features = torch.zeros((len(df),0))\n",
    "        for seq in [\"Neo_first3\", \"Neo_last3\", \"AseqCDR_3\", \"BseqCDR_3\"]:\n",
    "            # X_features = df[seq]\n",
    "            # print(df[seq].values.shape)\n",
    "            # convert the df[seq] into torch tensor\n",
    "            X_features = torch.cat((X_features, \n",
    "            torch.from_numpy(np.vstack(df[seq].values))), dim=1)\n",
    "        \n",
    "        X = torch.cat((torch.from_numpy(X_HLA_encoded), X_features), dim=1)\n",
    "        # encode the class label\n",
    "        y = df[\"Class\"].apply(lambda x: 1 if x == \"positive\" else 0).values\n",
    "\n",
    "        self.X = X\n",
    "        self.y = torch.from_numpy(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for test\n",
    "file_path = \"~/data/project/data/seqData/230221.csv\"\n",
    "df = pd.read_csv(file_path, index_col=0)\n",
    "# get the CDR3 region\n",
    "for chain in [\"AseqCDR\", \"BseqCDR\"]:\n",
    "    # df[chain+\"_1\"] = df[chain].str.split(\"_\").str[0]\n",
    "    # df[chain+\"_2\"] = df[chain].str.split(\"_\").str[1]\n",
    "    df[chain+\"_3\"] = df[chain].str.split(\"_\").str[2]\n",
    "    df.drop(columns=[chain], inplace=True)\n",
    "# delete the index\n",
    "df_ps = df[df[\"Class\"] == \"positive\"]\n",
    "df_ng_ex = df[df[\"Class\"] == \"negative\"]\n",
    "df_ng_em = df.copy()\n",
    "df_ng_em = df_ng_em[df_ng_em[\"Class\"] == \"positive\"]\n",
    "df_ng_em[\"AseqCDR_3\"] = df_ng_em[\"AseqCDR_3\"].apply(lambda x: random.choice(list(set(df_ng_em[\"AseqCDR_3\"]) - set(x))))\n",
    "df_ng_em[\"BseqCDR_3\"] = df_ng_em[\"BseqCDR_3\"].apply(lambda x: random.choice(list(set(df_ng_em[\"BseqCDR_3\"]) - set(x))))\n",
    "df_ng = pd.concat([df_ng_em, df_ng_ex], axis=0)\n",
    "df_ng.index = range(len(df_ng))\n",
    "df = pd.concat([df_ps, df_ng], axis=0)\n",
    "# encode the Neo_first3, Neo_last3\n",
    "for seq in [\"Neo_first3\", \"Neo_last3\"]:\n",
    "    df[seq] = df[seq].apply(lambda x: encode_seqCDR(x))\n",
    "# encode the CDR3 region\n",
    "len_map = {\n",
    "    \"AseqCDR_3\": df[\"AseqCDR_3\"].apply(lambda x: len(x)).max(),\n",
    "    \"BseqCDR_3\": df[\"BseqCDR_3\"].apply(lambda x: len(x)).max(),\n",
    "}\n",
    "for chain in [\"AseqCDR_3\", \"BseqCDR_3\"]:\n",
    "    length = len_map[chain]\n",
    "    # print(length)\n",
    "    df[chain] = df[chain].apply(lambda x: x + \"*\" * (length - len(x)))\n",
    "    df[chain] = df[chain].apply(lambda x: encode_seqCDR(x).reshape(1, -1))\n",
    "\n",
    "# encode HLA type through one-hot encoding\n",
    "X_HLA = df[\"HLA\"].values.reshape(-1, 1)\n",
    "HLAencoder = OneHotEncoder()\n",
    "X_HLA_encoded = HLAencoder.fit_transform(X_HLA).toarray()\n",
    "\n",
    "# put the features together including encoded HLA type, Neo_first3, Neo_last3, and CDR3 region\n",
    "X = np.concatenate((X_HLA_encoded, df[[\"Neo_first3\", \"Neo_last3\", \"AseqCDR_3\", \"BseqCDR_3\"]].values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the object data into torch tensor\n",
    "# np.hstack([X_HLA_encoded, df[[\"Neo_first3\", \"Neo_last3\", \"AseqCDR_3\", \"BseqCDR_3\"]]]).shape\n",
    "X_features = torch.zeros((len(df),0))\n",
    "for seq in [\"Neo_first3\", \"Neo_last3\", \"AseqCDR_3\", \"BseqCDR_3\"]:\n",
    "    # X_features = df[seq]\n",
    "    # print(df[seq].values.shape)\n",
    "    # convert the df[seq] into torch tensor\n",
    "    X_features = torch.cat((X_features, torch.from_numpy(np.vstack(df[seq].values))), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2755, 235])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[\"Neo_first3\"].values\n",
    "X_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"~/data/project/data/seqData/230221.csv\"\n",
    "TCRData = TCRDataset(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful functions and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the sequence are similar, (the length of the sequence are different less than 5 aa) into a batch, and then use the autoencoder to encode the HLA sequence.\n",
    "\n",
    "class LenMatchBatchSampler(data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "        buckets = [[] for i in range(300)]\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            count_zeros = int(torch.sum(self.sampler.data_source[idx] == 0) / 5)\n",
    "            buckets[count_zeros].append(idx)\n",
    "\n",
    "            if len(buckets[count_zeros]) == self.batch_size:\n",
    "                batch = list(buckets[count_zeros])\n",
    "                yield batch\n",
    "                buckets[count_zeros] = []\n",
    "\n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yield batch\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not use\n",
    "# random_seq_len = [random.randint(i) for i in range(5)]\n",
    "test_input = torch.empty(0)\n",
    "for i in range(5):\n",
    "    random_seq_len = random.randint(0, 300)\n",
    "    input = torch.randint(5, 100, (1, random_seq_len))\n",
    "    test_input = torch.cat((test_input, input), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # not use\n",
    "# # My may need to find a proper way to encode the HLA aa sequence, because there are 10 to 20 different HLA types and some of them have variants which are just one single aa difference.\n",
    "# hla_list = list(set(df[\"HLA\"]))\n",
    "# hla_list.sort()\n",
    "# hla_dict = dict()\n",
    "# for i in range(len(hla_list)):\n",
    "#     hla_dict[hla_list[i]] = i\n",
    "# # The encoding could apply autoencoder to encode the HLA sequence.\n",
    "# df[\"HLA_encode\"] = df[\"HLA\"].map(hla_dict)\n",
    "# X_feature = np.hstack((X_feature, df[\"HLA_encode\"].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 415])\n"
     ]
    }
   ],
   "source": [
    "# torch.randint(0, 10, (3, 5))\n",
    "# torch.randperm(10)\n",
    "random_seq_len = random.randint(0, 300)\n",
    "input = torch.randint(0, 100, (1, 5*random_seq_len))\n",
    "print(input.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9a3d897ef0b1e7415fe4468808571913e41281b79a56511723d411ccb064e7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
