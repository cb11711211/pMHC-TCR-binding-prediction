{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuxinchao/.conda/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tqdm\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_seqCDR(seqCDR):\n",
    "    encoding_list = []\n",
    "    for i in range(len(seqCDR)):\n",
    "        if seqCDR[i] == \"*\":\n",
    "            encoding_list.append(np.zeros(5).reshape(1,5))\n",
    "        else:\n",
    "            encoding_list.append(af.loc[seqCDR[i]].values.reshape(1,5))\n",
    "    return np.array(encoding_list).reshape(1,-1)\n",
    "\n",
    "af = pd.read_csv(\"~/data/project/pMHC-TCR/library/Atchley_factors.csv\")\n",
    "af.index = af[\"Amino acid\"]\n",
    "af.drop(columns=[\"Amino acid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pMHC_TCRDataset(Dataset):\n",
    "    def __init__(self, file_path, only_TCR_seq=False, only_experimental=False):\n",
    "        # super(TCRDataset, self).__init__()\n",
    "        df = pd.read_csv(file_path, index_col=0)\n",
    "        # get the CDR3 region\n",
    "        for chain in [\"AseqCDR\", \"BseqCDR\"]:\n",
    "            # df[chain+\"_1\"] = df[chain].str.split(\"_\").str[0]\n",
    "            # df[chain+\"_2\"] = df[chain].str.split(\"_\").str[1]\n",
    "            df[chain+\"_3\"] = df[chain].str.split(\"_\").str[2]\n",
    "            df.drop(columns=[chain], inplace=True)\n",
    "\n",
    "        # generate emulated negative samples \n",
    "        if not only_experimental:\n",
    "            df_ps = df[df[\"Class\"] == \"positive\"]\n",
    "            df_ng_ex = df[df[\"Class\"] == \"negative\"]\n",
    "            df_ng_em = df.copy()\n",
    "            df_ng_em = df_ng_em[df_ng_em[\"Class\"] == \"positive\"]\n",
    "            df_ng_em[\"AseqCDR_3\"] = df_ng_em[\"AseqCDR_3\"].apply(lambda x: random.choice(list(set(df_ng_em[\"AseqCDR_3\"]) - set(x))))\n",
    "            df_ng_em[\"BseqCDR_3\"] = df_ng_em[\"BseqCDR_3\"].apply(lambda x: random.choice(list(set(df_ng_em[\"BseqCDR_3\"]) - set(x))))\n",
    "            df_ng = pd.concat([df_ng_em, df_ng_ex], axis=0)\n",
    "            df_ng.index = range(len(df_ng))\n",
    "            df = pd.concat([df_ps, df_ng], axis=0)\n",
    "\n",
    "        # encode the Neo_first3, Neo_last3\n",
    "        for seq in [\"Neo_first3\", \"Neo_last3\"]:\n",
    "            df[seq] = df[seq].apply(lambda x: encode_seqCDR(x))\n",
    "        # encode the CDR3 region\n",
    "        len_map = {\n",
    "            \"AseqCDR_3\": df[\"AseqCDR_3\"].apply(lambda x: len(x)).max(),\n",
    "            \"BseqCDR_3\": df[\"BseqCDR_3\"].apply(lambda x: len(x)).max(),\n",
    "        }\n",
    "        for chain in [\"AseqCDR_3\", \"BseqCDR_3\"]:\n",
    "            length = len_map[chain]\n",
    "            df[chain] = df[chain].apply(lambda x: x + \"*\" * (length - len(x)))\n",
    "            df[chain] = df[chain].apply(lambda x: encode_seqCDR(x))\n",
    "\n",
    "        # encode HLA type through one-hot encoding\n",
    "        X_HLA = df[\"HLA\"].values.reshape(-1, 1)\n",
    "        HLAencoder = OneHotEncoder()\n",
    "        X_HLA_encoded = HLAencoder.fit_transform(X_HLA).toarray()\n",
    "\n",
    "        X_features = torch.zeros((len(df),0))\n",
    "        for seq in [\"Neo_first3\", \"Neo_last3\", \"AseqCDR_3\", \"BseqCDR_3\"]:\n",
    "            # X_features = df[seq]\n",
    "            # print(df[seq].values.shape)\n",
    "            # convert the df[seq] into torch tensor\n",
    "            X_features = torch.cat((X_features, \n",
    "            torch.from_numpy(np.vstack(df[seq].values))), dim=1)\n",
    "        \n",
    "        X = torch.cat((torch.from_numpy(X_HLA_encoded), X_features), dim=1)\n",
    "        # encode the class label\n",
    "        y = df[\"Class\"].apply(lambda x: 1 if x == \"positive\" else 0).values\n",
    "\n",
    "        if only_TCR_seq:\n",
    "            self.X = X_features\n",
    "            self.y = torch.from_numpy(y).float()\n",
    "        else:\n",
    "            self.X = X\n",
    "            self.y = torch.from_numpy(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pMHC_TCR_model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 hidden_size=16, \n",
    "                 batch_size=32, \n",
    "                 num_layers=2, \n",
    "                 device=\"cpu\", \n",
    "                 use_whole_data=False) -> None:\n",
    "        super(pMHC_TCR_model, self).__init__()\n",
    "        if use_whole_data:\n",
    "            self.batch_size = 0\n",
    "        else:\n",
    "            self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        # self.label = nn.Linear(hidden_size, 1)\n",
    "        self.linear_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size, int(hidden_size/2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(hidden_size/2), int(hidden_size/4)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(hidden_size/4), int(hidden_size/8)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(hidden_size/8), 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.batch_size == 0:\n",
    "            self.batch_size = input.shape[0]\n",
    "            x = input.float()\n",
    "            h_0 = Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(self.device))\n",
    "            c_0 = Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(self.device))\n",
    "            output, (h_n, c_n) = self.lstm(x, (h_0, c_0))\n",
    "            # pred = self.label(output[-1])\n",
    "            pred = self.linear_layer(output[-1])\n",
    "        else:\n",
    "            x = input.view(-1, self.batch_size, self.input_size).float()\n",
    "            h_0 = Variable(torch.zeros(self.num_layers * 1, self.batch_size, self.hidden_size).to(self.device))\n",
    "            c_0 = Variable(torch.zeros(self.num_layers * 1, self.batch_size, self.hidden_size).to(self.device))\n",
    "            output, (hn, cn) = self.lstm(x, (h_0, c_0))\n",
    "            # pred = self.label(output[-1])\n",
    "            pred = self.linear_layer(output[-1])\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(fold, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # print(output.shape, target.shape)\n",
    "        output = output.to(torch.float32)\n",
    "        target = target.to(torch.float32).view(-1, 1)\n",
    "        # print(output.shape, target.shape)\n",
    "        loss = nn.CrossEntropyLoss()(output.view(1,-1), target.view(1,-1))\n",
    "        train_loss += loss.item() / len(train_loader.dataset)  # sum up batch loss\n",
    "        pred = output.sigmoid().round()\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Fold/Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                fold, epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(train_loader.dataset)))\n",
    "    # return the average loss\n",
    "    # print(f\"The batch size is {model.batch_size}\")\n",
    "    return train_loss, correct / len(train_loader.dataset)\n",
    "\n",
    "def test(fold, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data).to(torch.float32)\n",
    "            target = target.to(torch.float32).view(-1, 1)\n",
    "            test_loss += nn.CrossEntropyLoss()(output.reshape(1,-1), target.reshape(1,-1)).item()  # sum up batch loss\n",
    "            # print(test_loss)\n",
    "            pred = output.sigmoid().round()\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= model.batch_size\n",
    "    print(f\"Test set for fold{fold}: Average Loss: \\\n",
    "          {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} \\\n",
    "          ({100. * correct / len(test_loader.dataset):.0f}%)\")\n",
    "    # print(f\"The length of test_loader is {len(test_loader)}\")\n",
    "    return test_loss, correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"~/data/project/data/seqData/230221.csv\"\n",
    "TCRData = pMHC_TCRDataset(file_path, only_TCR_seq=False, only_experimental=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 for training\n",
      "-------------------Fold 0-------------------\n",
      "Train Fold/Epoch: 0/1 [0/1646 (0%)]\tLoss: 0.098540\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/2 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/3 [0/1646 (0%)]\tLoss: 0.101066\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/4 [0/1646 (0%)]\tLoss: 0.106120\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/5 [0/1646 (0%)]\tLoss: 0.128860\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/6 [0/1646 (0%)]\tLoss: 0.113700\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/7 [0/1646 (0%)]\tLoss: 0.103593\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.8413, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 0/8 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/9 [0/1646 (0%)]\tLoss: 0.096013\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/10 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/11 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/12 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/13 [0/1646 (0%)]\tLoss: 0.098540\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/14 [0/1646 (0%)]\tLoss: 0.106120\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/15 [0/1646 (0%)]\tLoss: 0.113700\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/16 [0/1646 (0%)]\tLoss: 0.096013\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.7763, Accuracy: 108/1646           (7%)\n",
      "Train Fold/Epoch: 0/17 [0/1646 (0%)]\tLoss: 0.098540\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.8413, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 0/18 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/19 [0/1646 (0%)]\tLoss: 0.106120\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/20 [0/1646 (0%)]\tLoss: 0.106120\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/21 [0/1646 (0%)]\tLoss: 0.121280\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.8413, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 0/22 [0/1646 (0%)]\tLoss: 0.103593\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/23 [0/1646 (0%)]\tLoss: 0.118753\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/24 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/25 [0/1646 (0%)]\tLoss: 0.113700\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/26 [0/1646 (0%)]\tLoss: 0.103593\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/27 [0/1646 (0%)]\tLoss: 0.118753\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.8413, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 0/28 [0/1646 (0%)]\tLoss: 0.118753\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/29 [0/1646 (0%)]\tLoss: 0.118753\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1662, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 0/30 [0/1646 (0%)]\tLoss: 0.123806\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/31 [0/1646 (0%)]\tLoss: 0.106120\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/32 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/33 [0/1646 (0%)]\tLoss: 0.103593\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/34 [0/1646 (0%)]\tLoss: 0.106120\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/35 [0/1646 (0%)]\tLoss: 0.123806\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/36 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/37 [0/1646 (0%)]\tLoss: 0.116226\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/38 [0/1646 (0%)]\tLoss: 0.106120\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/39 [0/1646 (0%)]\tLoss: 0.113700\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.8413, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 0/40 [0/1646 (0%)]\tLoss: 0.113700\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/41 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.7763, Accuracy: 108/1646           (7%)\n",
      "Train Fold/Epoch: 0/42 [0/1646 (0%)]\tLoss: 0.103593\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/43 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1662, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 0/44 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/45 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/46 [0/1646 (0%)]\tLoss: 0.101066\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.8413, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 0/47 [0/1646 (0%)]\tLoss: 0.103593\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1662, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 0/48 [0/1646 (0%)]\tLoss: 0.101066\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/49 [0/1646 (0%)]\tLoss: 0.101066\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/50 [0/1646 (0%)]\tLoss: 0.113700\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.8413, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 0/51 [0/1646 (0%)]\tLoss: 0.098540\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/52 [0/1646 (0%)]\tLoss: 0.093486\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/53 [0/1646 (0%)]\tLoss: 0.101066\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/54 [0/1646 (0%)]\tLoss: 0.126333\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/55 [0/1646 (0%)]\tLoss: 0.121280\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/56 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/57 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.8413, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 0/58 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/59 [0/1646 (0%)]\tLoss: 0.113700\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/60 [0/1646 (0%)]\tLoss: 0.116226\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/61 [0/1646 (0%)]\tLoss: 0.131386\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/62 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/63 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/64 [0/1646 (0%)]\tLoss: 0.116226\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/65 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/66 [0/1646 (0%)]\tLoss: 0.113700\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/67 [0/1646 (0%)]\tLoss: 0.090960\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/68 [0/1646 (0%)]\tLoss: 0.128860\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.8413, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 0/69 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/70 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/71 [0/1646 (0%)]\tLoss: 0.098540\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/72 [0/1646 (0%)]\tLoss: 0.096013\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/73 [0/1646 (0%)]\tLoss: 0.116226\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1662, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 0/74 [0/1646 (0%)]\tLoss: 0.083380\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/75 [0/1646 (0%)]\tLoss: 0.106120\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/76 [0/1646 (0%)]\tLoss: 0.103593\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/77 [0/1646 (0%)]\tLoss: 0.116226\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/78 [0/1646 (0%)]\tLoss: 0.113700\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/79 [0/1646 (0%)]\tLoss: 0.118753\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/80 [0/1646 (0%)]\tLoss: 0.096013\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/81 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/82 [0/1646 (0%)]\tLoss: 0.098540\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/83 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/84 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/85 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.8413, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 0/86 [0/1646 (0%)]\tLoss: 0.096013\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/87 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/88 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/89 [0/1646 (0%)]\tLoss: 0.096013\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/90 [0/1646 (0%)]\tLoss: 0.106120\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/91 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/92 [0/1646 (0%)]\tLoss: 0.098540\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 0/93 [0/1646 (0%)]\tLoss: 0.118753\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/94 [0/1646 (0%)]\tLoss: 0.113700\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9063, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 0/95 [0/1646 (0%)]\tLoss: 0.103593\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/96 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/97 [0/1646 (0%)]\tLoss: 0.088433\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/98 [0/1646 (0%)]\tLoss: 0.121280\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           13.9712, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 0/99 [0/1646 (0%)]\tLoss: 0.108646\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.1012, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 0/100 [0/1646 (0%)]\tLoss: 0.111173\n",
      "The batch size is 64\n",
      "Test set for fold0: Average Loss:           14.0362, Accuracy: 104/1646           (6%)\n",
      "-------------------Fold 1-------------------\n",
      "Train Fold/Epoch: 1/1 [0/1646 (0%)]\tLoss: 0.121279\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           13.9582, Accuracy: 215/1646           (13%)\n",
      "Train Fold/Epoch: 1/2 [0/1646 (0%)]\tLoss: 0.100962\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           13.9304, Accuracy: 238/1646           (14%)\n",
      "Train Fold/Epoch: 1/3 [0/1646 (0%)]\tLoss: 0.101468\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           13.9465, Accuracy: 220/1646           (13%)\n",
      "Train Fold/Epoch: 1/4 [0/1646 (0%)]\tLoss: 0.106070\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           13.8499, Accuracy: 250/1646           (15%)\n",
      "Train Fold/Epoch: 1/5 [0/1646 (0%)]\tLoss: 0.103803\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           13.7020, Accuracy: 261/1646           (16%)\n",
      "Train Fold/Epoch: 1/6 [0/1646 (0%)]\tLoss: 0.083737\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.0180, Accuracy: 259/1646           (16%)\n",
      "Train Fold/Epoch: 1/7 [0/1646 (0%)]\tLoss: 0.089436\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           13.6861, Accuracy: 266/1646           (16%)\n",
      "Train Fold/Epoch: 1/8 [0/1646 (0%)]\tLoss: 0.080578\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           13.8473, Accuracy: 264/1646           (16%)\n",
      "Train Fold/Epoch: 1/9 [0/1646 (0%)]\tLoss: 0.102239\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           13.7764, Accuracy: 270/1646           (16%)\n",
      "Train Fold/Epoch: 1/10 [0/1646 (0%)]\tLoss: 0.115170\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.1186, Accuracy: 265/1646           (16%)\n",
      "Train Fold/Epoch: 1/11 [0/1646 (0%)]\tLoss: 0.117075\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.3686, Accuracy: 263/1646           (16%)\n",
      "Train Fold/Epoch: 1/12 [0/1646 (0%)]\tLoss: 0.101040\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.0265, Accuracy: 271/1646           (16%)\n",
      "Train Fold/Epoch: 1/13 [0/1646 (0%)]\tLoss: 0.105676\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.3979, Accuracy: 274/1646           (17%)\n",
      "Train Fold/Epoch: 1/14 [0/1646 (0%)]\tLoss: 0.111162\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.1027, Accuracy: 271/1646           (16%)\n",
      "Train Fold/Epoch: 1/15 [0/1646 (0%)]\tLoss: 0.096763\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.2517, Accuracy: 267/1646           (16%)\n",
      "Train Fold/Epoch: 1/16 [0/1646 (0%)]\tLoss: 0.110151\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.4959, Accuracy: 268/1646           (16%)\n",
      "Train Fold/Epoch: 1/17 [0/1646 (0%)]\tLoss: 0.099225\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.3550, Accuracy: 271/1646           (16%)\n",
      "Train Fold/Epoch: 1/18 [0/1646 (0%)]\tLoss: 0.106201\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.3544, Accuracy: 269/1646           (16%)\n",
      "Train Fold/Epoch: 1/19 [0/1646 (0%)]\tLoss: 0.097512\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.4553, Accuracy: 269/1646           (16%)\n",
      "Train Fold/Epoch: 1/20 [0/1646 (0%)]\tLoss: 0.096908\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.2140, Accuracy: 271/1646           (16%)\n",
      "Train Fold/Epoch: 1/21 [0/1646 (0%)]\tLoss: 0.090843\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.5402, Accuracy: 267/1646           (16%)\n",
      "Train Fold/Epoch: 1/22 [0/1646 (0%)]\tLoss: 0.098995\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.3489, Accuracy: 268/1646           (16%)\n",
      "Train Fold/Epoch: 1/23 [0/1646 (0%)]\tLoss: 0.108345\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.5327, Accuracy: 266/1646           (16%)\n",
      "Train Fold/Epoch: 1/24 [0/1646 (0%)]\tLoss: 0.103211\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.2359, Accuracy: 266/1646           (16%)\n",
      "Train Fold/Epoch: 1/25 [0/1646 (0%)]\tLoss: 0.090857\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.4617, Accuracy: 268/1646           (16%)\n",
      "Train Fold/Epoch: 1/26 [0/1646 (0%)]\tLoss: 0.106445\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.5195, Accuracy: 270/1646           (16%)\n",
      "Train Fold/Epoch: 1/27 [0/1646 (0%)]\tLoss: 0.102667\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.4671, Accuracy: 272/1646           (17%)\n",
      "Train Fold/Epoch: 1/28 [0/1646 (0%)]\tLoss: 0.091212\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.6074, Accuracy: 267/1646           (16%)\n",
      "Train Fold/Epoch: 1/29 [0/1646 (0%)]\tLoss: 0.095979\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.7629, Accuracy: 264/1646           (16%)\n",
      "Train Fold/Epoch: 1/30 [0/1646 (0%)]\tLoss: 0.099623\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.6398, Accuracy: 279/1646           (17%)\n",
      "Train Fold/Epoch: 1/31 [0/1646 (0%)]\tLoss: 0.099680\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.3256, Accuracy: 277/1646           (17%)\n",
      "Train Fold/Epoch: 1/32 [0/1646 (0%)]\tLoss: 0.091425\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.4326, Accuracy: 274/1646           (17%)\n",
      "Train Fold/Epoch: 1/33 [0/1646 (0%)]\tLoss: 0.080387\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.6561, Accuracy: 273/1646           (17%)\n",
      "Train Fold/Epoch: 1/34 [0/1646 (0%)]\tLoss: 0.101776\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.7429, Accuracy: 270/1646           (16%)\n",
      "Train Fold/Epoch: 1/35 [0/1646 (0%)]\tLoss: 0.110575\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.6694, Accuracy: 269/1646           (16%)\n",
      "Train Fold/Epoch: 1/36 [0/1646 (0%)]\tLoss: 0.096847\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.7974, Accuracy: 268/1646           (16%)\n",
      "Train Fold/Epoch: 1/37 [0/1646 (0%)]\tLoss: 0.101372\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.4705, Accuracy: 272/1646           (17%)\n",
      "Train Fold/Epoch: 1/38 [0/1646 (0%)]\tLoss: 0.102047\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.5390, Accuracy: 268/1646           (16%)\n",
      "Train Fold/Epoch: 1/39 [0/1646 (0%)]\tLoss: 0.085735\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.7779, Accuracy: 271/1646           (16%)\n",
      "Train Fold/Epoch: 1/40 [0/1646 (0%)]\tLoss: 0.096854\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.6442, Accuracy: 269/1646           (16%)\n",
      "Train Fold/Epoch: 1/41 [0/1646 (0%)]\tLoss: 0.096083\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.6504, Accuracy: 273/1646           (17%)\n",
      "Train Fold/Epoch: 1/42 [0/1646 (0%)]\tLoss: 0.120037\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.6673, Accuracy: 274/1646           (17%)\n",
      "Train Fold/Epoch: 1/43 [0/1646 (0%)]\tLoss: 0.102117\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9449, Accuracy: 270/1646           (16%)\n",
      "Train Fold/Epoch: 1/44 [0/1646 (0%)]\tLoss: 0.084605\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.8310, Accuracy: 271/1646           (16%)\n",
      "Train Fold/Epoch: 1/45 [0/1646 (0%)]\tLoss: 0.100818\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.8200, Accuracy: 270/1646           (16%)\n",
      "Train Fold/Epoch: 1/46 [0/1646 (0%)]\tLoss: 0.117747\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.0382, Accuracy: 272/1646           (17%)\n",
      "Train Fold/Epoch: 1/47 [0/1646 (0%)]\tLoss: 0.092191\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.0086, Accuracy: 277/1646           (17%)\n",
      "Train Fold/Epoch: 1/48 [0/1646 (0%)]\tLoss: 0.101498\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.7973, Accuracy: 268/1646           (16%)\n",
      "Train Fold/Epoch: 1/49 [0/1646 (0%)]\tLoss: 0.105436\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9610, Accuracy: 269/1646           (16%)\n",
      "Train Fold/Epoch: 1/50 [0/1646 (0%)]\tLoss: 0.109525\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.7879, Accuracy: 271/1646           (16%)\n",
      "Train Fold/Epoch: 1/51 [0/1646 (0%)]\tLoss: 0.092145\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9414, Accuracy: 276/1646           (17%)\n",
      "Train Fold/Epoch: 1/52 [0/1646 (0%)]\tLoss: 0.104771\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.0348, Accuracy: 274/1646           (17%)\n",
      "Train Fold/Epoch: 1/53 [0/1646 (0%)]\tLoss: 0.095025\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9555, Accuracy: 272/1646           (17%)\n",
      "Train Fold/Epoch: 1/54 [0/1646 (0%)]\tLoss: 0.096212\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.7875, Accuracy: 268/1646           (16%)\n",
      "Train Fold/Epoch: 1/55 [0/1646 (0%)]\tLoss: 0.090246\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.0314, Accuracy: 267/1646           (16%)\n",
      "Train Fold/Epoch: 1/56 [0/1646 (0%)]\tLoss: 0.093102\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.1268, Accuracy: 267/1646           (16%)\n",
      "Train Fold/Epoch: 1/57 [0/1646 (0%)]\tLoss: 0.072494\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9558, Accuracy: 269/1646           (16%)\n",
      "Train Fold/Epoch: 1/58 [0/1646 (0%)]\tLoss: 0.098555\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.7004, Accuracy: 269/1646           (16%)\n",
      "Train Fold/Epoch: 1/59 [0/1646 (0%)]\tLoss: 0.095373\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.7760, Accuracy: 273/1646           (17%)\n",
      "Train Fold/Epoch: 1/60 [0/1646 (0%)]\tLoss: 0.110758\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9725, Accuracy: 272/1646           (17%)\n",
      "Train Fold/Epoch: 1/61 [0/1646 (0%)]\tLoss: 0.110632\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9629, Accuracy: 272/1646           (17%)\n",
      "Train Fold/Epoch: 1/62 [0/1646 (0%)]\tLoss: 0.102921\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.6520, Accuracy: 271/1646           (16%)\n",
      "Train Fold/Epoch: 1/63 [0/1646 (0%)]\tLoss: 0.093688\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9306, Accuracy: 275/1646           (17%)\n",
      "Train Fold/Epoch: 1/64 [0/1646 (0%)]\tLoss: 0.093425\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9926, Accuracy: 272/1646           (17%)\n",
      "Train Fold/Epoch: 1/65 [0/1646 (0%)]\tLoss: 0.096399\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9892, Accuracy: 269/1646           (16%)\n",
      "Train Fold/Epoch: 1/66 [0/1646 (0%)]\tLoss: 0.113620\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9269, Accuracy: 274/1646           (17%)\n",
      "Train Fold/Epoch: 1/67 [0/1646 (0%)]\tLoss: 0.096559\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.0043, Accuracy: 274/1646           (17%)\n",
      "Train Fold/Epoch: 1/68 [0/1646 (0%)]\tLoss: 0.079605\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.7227, Accuracy: 276/1646           (17%)\n",
      "Train Fold/Epoch: 1/69 [0/1646 (0%)]\tLoss: 0.082922\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.3112, Accuracy: 269/1646           (16%)\n",
      "Train Fold/Epoch: 1/70 [0/1646 (0%)]\tLoss: 0.107598\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.7850, Accuracy: 270/1646           (16%)\n",
      "Train Fold/Epoch: 1/71 [0/1646 (0%)]\tLoss: 0.120026\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9231, Accuracy: 271/1646           (16%)\n",
      "Train Fold/Epoch: 1/72 [0/1646 (0%)]\tLoss: 0.105537\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9407, Accuracy: 272/1646           (17%)\n",
      "Train Fold/Epoch: 1/73 [0/1646 (0%)]\tLoss: 0.095972\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.8563, Accuracy: 270/1646           (16%)\n",
      "Train Fold/Epoch: 1/74 [0/1646 (0%)]\tLoss: 0.108429\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9630, Accuracy: 272/1646           (17%)\n",
      "Train Fold/Epoch: 1/75 [0/1646 (0%)]\tLoss: 0.107164\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.1590, Accuracy: 265/1646           (16%)\n",
      "Train Fold/Epoch: 1/76 [0/1646 (0%)]\tLoss: 0.100039\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.7789, Accuracy: 275/1646           (17%)\n",
      "Train Fold/Epoch: 1/77 [0/1646 (0%)]\tLoss: 0.096172\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.0054, Accuracy: 276/1646           (17%)\n",
      "Train Fold/Epoch: 1/78 [0/1646 (0%)]\tLoss: 0.102597\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.0183, Accuracy: 269/1646           (16%)\n",
      "Train Fold/Epoch: 1/79 [0/1646 (0%)]\tLoss: 0.087753\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9846, Accuracy: 270/1646           (16%)\n",
      "Train Fold/Epoch: 1/80 [0/1646 (0%)]\tLoss: 0.118192\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.4523, Accuracy: 268/1646           (16%)\n",
      "Train Fold/Epoch: 1/81 [0/1646 (0%)]\tLoss: 0.082583\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.2403, Accuracy: 268/1646           (16%)\n",
      "Train Fold/Epoch: 1/82 [0/1646 (0%)]\tLoss: 0.093687\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.3732, Accuracy: 267/1646           (16%)\n",
      "Train Fold/Epoch: 1/83 [0/1646 (0%)]\tLoss: 0.082772\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.5748, Accuracy: 272/1646           (17%)\n",
      "Train Fold/Epoch: 1/84 [0/1646 (0%)]\tLoss: 0.115856\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.8257, Accuracy: 275/1646           (17%)\n",
      "Train Fold/Epoch: 1/85 [0/1646 (0%)]\tLoss: 0.103227\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9504, Accuracy: 271/1646           (16%)\n",
      "Train Fold/Epoch: 1/86 [0/1646 (0%)]\tLoss: 0.095132\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.2142, Accuracy: 270/1646           (16%)\n",
      "Train Fold/Epoch: 1/87 [0/1646 (0%)]\tLoss: 0.094453\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.8621, Accuracy: 270/1646           (16%)\n",
      "Train Fold/Epoch: 1/88 [0/1646 (0%)]\tLoss: 0.087989\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.5958, Accuracy: 271/1646           (16%)\n",
      "Train Fold/Epoch: 1/89 [0/1646 (0%)]\tLoss: 0.105024\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.2633, Accuracy: 269/1646           (16%)\n",
      "Train Fold/Epoch: 1/90 [0/1646 (0%)]\tLoss: 0.093981\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.2036, Accuracy: 268/1646           (16%)\n",
      "Train Fold/Epoch: 1/91 [0/1646 (0%)]\tLoss: 0.105539\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.1470, Accuracy: 270/1646           (16%)\n",
      "Train Fold/Epoch: 1/92 [0/1646 (0%)]\tLoss: 0.086412\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           14.9329, Accuracy: 272/1646           (17%)\n",
      "Train Fold/Epoch: 1/93 [0/1646 (0%)]\tLoss: 0.105456\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.1290, Accuracy: 272/1646           (17%)\n",
      "Train Fold/Epoch: 1/94 [0/1646 (0%)]\tLoss: 0.087612\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.3214, Accuracy: 272/1646           (17%)\n",
      "Train Fold/Epoch: 1/95 [0/1646 (0%)]\tLoss: 0.081768\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.3431, Accuracy: 269/1646           (16%)\n",
      "Train Fold/Epoch: 1/96 [0/1646 (0%)]\tLoss: 0.106997\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.0909, Accuracy: 273/1646           (17%)\n",
      "Train Fold/Epoch: 1/97 [0/1646 (0%)]\tLoss: 0.093687\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.2311, Accuracy: 273/1646           (17%)\n",
      "Train Fold/Epoch: 1/98 [0/1646 (0%)]\tLoss: 0.099305\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.1656, Accuracy: 274/1646           (17%)\n",
      "Train Fold/Epoch: 1/99 [0/1646 (0%)]\tLoss: 0.081172\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.2716, Accuracy: 269/1646           (16%)\n",
      "Train Fold/Epoch: 1/100 [0/1646 (0%)]\tLoss: 0.088560\n",
      "The batch size is 64\n",
      "Test set for fold1: Average Loss:           15.3921, Accuracy: 268/1646           (16%)\n",
      "-------------------Fold 2-------------------\n",
      "Train Fold/Epoch: 2/1 [0/1646 (0%)]\tLoss: 0.088331\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.7085, Accuracy: 299/1646           (18%)\n",
      "Train Fold/Epoch: 2/2 [0/1646 (0%)]\tLoss: 0.104977\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.1454, Accuracy: 289/1646           (18%)\n",
      "Train Fold/Epoch: 2/3 [0/1646 (0%)]\tLoss: 0.098777\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.2380, Accuracy: 283/1646           (17%)\n",
      "Train Fold/Epoch: 2/4 [0/1646 (0%)]\tLoss: 0.097500\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.1402, Accuracy: 288/1646           (17%)\n",
      "Train Fold/Epoch: 2/5 [0/1646 (0%)]\tLoss: 0.092982\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.1458, Accuracy: 283/1646           (17%)\n",
      "Train Fold/Epoch: 2/6 [0/1646 (0%)]\tLoss: 0.094370\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.2034, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/7 [0/1646 (0%)]\tLoss: 0.093753\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.1012, Accuracy: 284/1646           (17%)\n",
      "Train Fold/Epoch: 2/8 [0/1646 (0%)]\tLoss: 0.096370\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.0557, Accuracy: 287/1646           (17%)\n",
      "Train Fold/Epoch: 2/9 [0/1646 (0%)]\tLoss: 0.110246\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.0791, Accuracy: 287/1646           (17%)\n",
      "Train Fold/Epoch: 2/10 [0/1646 (0%)]\tLoss: 0.113164\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.2501, Accuracy: 290/1646           (18%)\n",
      "Train Fold/Epoch: 2/11 [0/1646 (0%)]\tLoss: 0.107408\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.2457, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/12 [0/1646 (0%)]\tLoss: 0.103752\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.3504, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/13 [0/1646 (0%)]\tLoss: 0.107610\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.2197, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/14 [0/1646 (0%)]\tLoss: 0.111276\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.1731, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/15 [0/1646 (0%)]\tLoss: 0.102630\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.2066, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/16 [0/1646 (0%)]\tLoss: 0.104898\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.3756, Accuracy: 290/1646           (18%)\n",
      "Train Fold/Epoch: 2/17 [0/1646 (0%)]\tLoss: 0.102628\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.1047, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/18 [0/1646 (0%)]\tLoss: 0.110036\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.2559, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/19 [0/1646 (0%)]\tLoss: 0.104443\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.2221, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/20 [0/1646 (0%)]\tLoss: 0.101711\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.1712, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/21 [0/1646 (0%)]\tLoss: 0.104435\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.1928, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/22 [0/1646 (0%)]\tLoss: 0.096731\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.2725, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/23 [0/1646 (0%)]\tLoss: 0.111123\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.2733, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/24 [0/1646 (0%)]\tLoss: 0.101510\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.1784, Accuracy: 295/1646           (18%)\n",
      "Train Fold/Epoch: 2/25 [0/1646 (0%)]\tLoss: 0.090264\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.2488, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/26 [0/1646 (0%)]\tLoss: 0.093516\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.2687, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/27 [0/1646 (0%)]\tLoss: 0.095487\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.4596, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/28 [0/1646 (0%)]\tLoss: 0.104904\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.2471, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/29 [0/1646 (0%)]\tLoss: 0.107153\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.4221, Accuracy: 291/1646           (18%)\n",
      "Train Fold/Epoch: 2/30 [0/1646 (0%)]\tLoss: 0.104394\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.3392, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/31 [0/1646 (0%)]\tLoss: 0.098350\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.4405, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/32 [0/1646 (0%)]\tLoss: 0.110163\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.1943, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/33 [0/1646 (0%)]\tLoss: 0.101481\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.4843, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/34 [0/1646 (0%)]\tLoss: 0.107384\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.3456, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/35 [0/1646 (0%)]\tLoss: 0.125467\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6252, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/36 [0/1646 (0%)]\tLoss: 0.090385\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.1788, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/37 [0/1646 (0%)]\tLoss: 0.102149\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.2949, Accuracy: 295/1646           (18%)\n",
      "Train Fold/Epoch: 2/38 [0/1646 (0%)]\tLoss: 0.112653\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6568, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/39 [0/1646 (0%)]\tLoss: 0.086898\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.3843, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/40 [0/1646 (0%)]\tLoss: 0.085055\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6783, Accuracy: 295/1646           (18%)\n",
      "Train Fold/Epoch: 2/41 [0/1646 (0%)]\tLoss: 0.099011\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5624, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/42 [0/1646 (0%)]\tLoss: 0.104546\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6536, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/43 [0/1646 (0%)]\tLoss: 0.107070\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.4857, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/44 [0/1646 (0%)]\tLoss: 0.101279\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5288, Accuracy: 295/1646           (18%)\n",
      "Train Fold/Epoch: 2/45 [0/1646 (0%)]\tLoss: 0.104147\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6525, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/46 [0/1646 (0%)]\tLoss: 0.090655\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6829, Accuracy: 295/1646           (18%)\n",
      "Train Fold/Epoch: 2/47 [0/1646 (0%)]\tLoss: 0.098434\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6784, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/48 [0/1646 (0%)]\tLoss: 0.107305\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6387, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/49 [0/1646 (0%)]\tLoss: 0.092699\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.4528, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/50 [0/1646 (0%)]\tLoss: 0.112961\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.3924, Accuracy: 295/1646           (18%)\n",
      "Train Fold/Epoch: 2/51 [0/1646 (0%)]\tLoss: 0.102258\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6193, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/52 [0/1646 (0%)]\tLoss: 0.095613\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5226, Accuracy: 297/1646           (18%)\n",
      "Train Fold/Epoch: 2/53 [0/1646 (0%)]\tLoss: 0.107277\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5796, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/54 [0/1646 (0%)]\tLoss: 0.107565\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6140, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/55 [0/1646 (0%)]\tLoss: 0.104147\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5429, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/56 [0/1646 (0%)]\tLoss: 0.107616\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6242, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/57 [0/1646 (0%)]\tLoss: 0.096676\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.4729, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/58 [0/1646 (0%)]\tLoss: 0.107506\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6485, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/59 [0/1646 (0%)]\tLoss: 0.090134\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5844, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/60 [0/1646 (0%)]\tLoss: 0.105104\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.7955, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/61 [0/1646 (0%)]\tLoss: 0.107071\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5594, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/62 [0/1646 (0%)]\tLoss: 0.098703\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.3815, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/63 [0/1646 (0%)]\tLoss: 0.115994\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5777, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/64 [0/1646 (0%)]\tLoss: 0.093091\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.8403, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/65 [0/1646 (0%)]\tLoss: 0.090376\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.8554, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/66 [0/1646 (0%)]\tLoss: 0.107131\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6997, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/67 [0/1646 (0%)]\tLoss: 0.118892\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.7152, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/68 [0/1646 (0%)]\tLoss: 0.086814\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6553, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/69 [0/1646 (0%)]\tLoss: 0.079452\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5654, Accuracy: 295/1646           (18%)\n",
      "Train Fold/Epoch: 2/70 [0/1646 (0%)]\tLoss: 0.104145\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.7404, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/71 [0/1646 (0%)]\tLoss: 0.122575\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.9333, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/72 [0/1646 (0%)]\tLoss: 0.093677\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6898, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/73 [0/1646 (0%)]\tLoss: 0.104117\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5202, Accuracy: 291/1646           (18%)\n",
      "Train Fold/Epoch: 2/74 [0/1646 (0%)]\tLoss: 0.110033\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.7623, Accuracy: 295/1646           (18%)\n",
      "Train Fold/Epoch: 2/75 [0/1646 (0%)]\tLoss: 0.107679\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5071, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/76 [0/1646 (0%)]\tLoss: 0.104425\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6020, Accuracy: 297/1646           (18%)\n",
      "Train Fold/Epoch: 2/77 [0/1646 (0%)]\tLoss: 0.101315\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6982, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/78 [0/1646 (0%)]\tLoss: 0.101286\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.7508, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/79 [0/1646 (0%)]\tLoss: 0.081353\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5706, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/80 [0/1646 (0%)]\tLoss: 0.110238\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6529, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/81 [0/1646 (0%)]\tLoss: 0.084074\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6779, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/82 [0/1646 (0%)]\tLoss: 0.068148\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6995, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/83 [0/1646 (0%)]\tLoss: 0.098492\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6284, Accuracy: 291/1646           (18%)\n",
      "Train Fold/Epoch: 2/84 [0/1646 (0%)]\tLoss: 0.122182\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5846, Accuracy: 291/1646           (18%)\n",
      "Train Fold/Epoch: 2/85 [0/1646 (0%)]\tLoss: 0.096569\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6017, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/86 [0/1646 (0%)]\tLoss: 0.095834\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6981, Accuracy: 291/1646           (18%)\n",
      "Train Fold/Epoch: 2/87 [0/1646 (0%)]\tLoss: 0.107698\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6189, Accuracy: 291/1646           (18%)\n",
      "Train Fold/Epoch: 2/88 [0/1646 (0%)]\tLoss: 0.099036\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5872, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/89 [0/1646 (0%)]\tLoss: 0.084389\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6204, Accuracy: 291/1646           (18%)\n",
      "Train Fold/Epoch: 2/90 [0/1646 (0%)]\tLoss: 0.109659\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.9122, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/91 [0/1646 (0%)]\tLoss: 0.107079\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6677, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/92 [0/1646 (0%)]\tLoss: 0.113112\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.7139, Accuracy: 291/1646           (18%)\n",
      "Train Fold/Epoch: 2/93 [0/1646 (0%)]\tLoss: 0.092924\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6638, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/94 [0/1646 (0%)]\tLoss: 0.093090\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6279, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 2/95 [0/1646 (0%)]\tLoss: 0.098352\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.6746, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/96 [0/1646 (0%)]\tLoss: 0.087625\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.7404, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/97 [0/1646 (0%)]\tLoss: 0.104089\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.8129, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/98 [0/1646 (0%)]\tLoss: 0.101616\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.5952, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 2/99 [0/1646 (0%)]\tLoss: 0.107331\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.8171, Accuracy: 293/1646           (18%)\n",
      "Train Fold/Epoch: 2/100 [0/1646 (0%)]\tLoss: 0.098449\n",
      "The batch size is 64\n",
      "Test set for fold2: Average Loss:           13.7798, Accuracy: 294/1646           (18%)\n",
      "-------------------Fold 3-------------------\n",
      "Train Fold/Epoch: 3/1 [0/1646 (0%)]\tLoss: 0.101110\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           14.0559, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 3/2 [0/1646 (0%)]\tLoss: 0.112952\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           13.2496, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/3 [0/1646 (0%)]\tLoss: 0.091520\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           13.0823, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 3/4 [0/1646 (0%)]\tLoss: 0.088953\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8340, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/5 [0/1646 (0%)]\tLoss: 0.095152\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7650, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 3/6 [0/1646 (0%)]\tLoss: 0.083838\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9629, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/7 [0/1646 (0%)]\tLoss: 0.105106\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8671, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/8 [0/1646 (0%)]\tLoss: 0.113597\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7022, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 3/9 [0/1646 (0%)]\tLoss: 0.084885\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7426, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 3/10 [0/1646 (0%)]\tLoss: 0.088654\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8303, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/11 [0/1646 (0%)]\tLoss: 0.104096\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7624, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/12 [0/1646 (0%)]\tLoss: 0.107352\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           13.0024, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 3/13 [0/1646 (0%)]\tLoss: 0.095517\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8612, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/14 [0/1646 (0%)]\tLoss: 0.093121\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9510, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/15 [0/1646 (0%)]\tLoss: 0.099803\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9463, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/16 [0/1646 (0%)]\tLoss: 0.084608\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8334, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/17 [0/1646 (0%)]\tLoss: 0.098735\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9557, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/18 [0/1646 (0%)]\tLoss: 0.082728\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9401, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/19 [0/1646 (0%)]\tLoss: 0.102183\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9177, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/20 [0/1646 (0%)]\tLoss: 0.101608\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8978, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/21 [0/1646 (0%)]\tLoss: 0.102174\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8316, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/22 [0/1646 (0%)]\tLoss: 0.114129\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8885, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/23 [0/1646 (0%)]\tLoss: 0.088151\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9492, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/24 [0/1646 (0%)]\tLoss: 0.101798\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8070, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/25 [0/1646 (0%)]\tLoss: 0.098966\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8877, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/26 [0/1646 (0%)]\tLoss: 0.104171\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8495, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/27 [0/1646 (0%)]\tLoss: 0.104849\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8526, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/28 [0/1646 (0%)]\tLoss: 0.088034\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8456, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/29 [0/1646 (0%)]\tLoss: 0.087666\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           13.0014, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 3/30 [0/1646 (0%)]\tLoss: 0.113710\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7244, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 3/31 [0/1646 (0%)]\tLoss: 0.095981\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8611, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/32 [0/1646 (0%)]\tLoss: 0.087765\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9452, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/33 [0/1646 (0%)]\tLoss: 0.087415\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7890, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/34 [0/1646 (0%)]\tLoss: 0.099578\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9578, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/35 [0/1646 (0%)]\tLoss: 0.089949\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9310, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/36 [0/1646 (0%)]\tLoss: 0.099168\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7045, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 3/37 [0/1646 (0%)]\tLoss: 0.098886\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8369, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/38 [0/1646 (0%)]\tLoss: 0.086997\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9794, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 3/39 [0/1646 (0%)]\tLoss: 0.098442\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8586, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/40 [0/1646 (0%)]\tLoss: 0.102614\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           13.0541, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 3/41 [0/1646 (0%)]\tLoss: 0.101356\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8809, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/42 [0/1646 (0%)]\tLoss: 0.105059\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           13.0010, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 3/43 [0/1646 (0%)]\tLoss: 0.096030\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9050, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/44 [0/1646 (0%)]\tLoss: 0.082187\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7566, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/45 [0/1646 (0%)]\tLoss: 0.102096\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8472, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/46 [0/1646 (0%)]\tLoss: 0.104573\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9185, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/47 [0/1646 (0%)]\tLoss: 0.085934\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7606, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/48 [0/1646 (0%)]\tLoss: 0.082260\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8487, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/49 [0/1646 (0%)]\tLoss: 0.101628\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7139, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 3/50 [0/1646 (0%)]\tLoss: 0.089950\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7144, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 3/51 [0/1646 (0%)]\tLoss: 0.122396\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.6926, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 3/52 [0/1646 (0%)]\tLoss: 0.104219\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8443, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/53 [0/1646 (0%)]\tLoss: 0.092661\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9964, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 3/54 [0/1646 (0%)]\tLoss: 0.102412\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.6292, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 3/55 [0/1646 (0%)]\tLoss: 0.082568\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9276, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/56 [0/1646 (0%)]\tLoss: 0.104763\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8840, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/57 [0/1646 (0%)]\tLoss: 0.099422\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7777, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/58 [0/1646 (0%)]\tLoss: 0.107709\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8659, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/59 [0/1646 (0%)]\tLoss: 0.086894\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7421, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 3/60 [0/1646 (0%)]\tLoss: 0.121977\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9281, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/61 [0/1646 (0%)]\tLoss: 0.082782\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8154, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/62 [0/1646 (0%)]\tLoss: 0.099485\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9403, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/63 [0/1646 (0%)]\tLoss: 0.111103\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8714, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/64 [0/1646 (0%)]\tLoss: 0.092521\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8798, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/65 [0/1646 (0%)]\tLoss: 0.101803\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8721, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/66 [0/1646 (0%)]\tLoss: 0.099362\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9544, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/67 [0/1646 (0%)]\tLoss: 0.107531\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8699, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/68 [0/1646 (0%)]\tLoss: 0.098854\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8724, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/69 [0/1646 (0%)]\tLoss: 0.107518\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8781, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/70 [0/1646 (0%)]\tLoss: 0.098347\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.6713, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 3/71 [0/1646 (0%)]\tLoss: 0.080510\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9597, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/72 [0/1646 (0%)]\tLoss: 0.093614\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8935, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/73 [0/1646 (0%)]\tLoss: 0.089875\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           13.0195, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/74 [0/1646 (0%)]\tLoss: 0.096346\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8369, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/75 [0/1646 (0%)]\tLoss: 0.107139\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9140, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/76 [0/1646 (0%)]\tLoss: 0.099258\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8360, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/77 [0/1646 (0%)]\tLoss: 0.107496\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9017, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/78 [0/1646 (0%)]\tLoss: 0.080167\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           13.0593, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 3/79 [0/1646 (0%)]\tLoss: 0.089905\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9831, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/80 [0/1646 (0%)]\tLoss: 0.108262\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9139, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/81 [0/1646 (0%)]\tLoss: 0.107152\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.6776, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 3/82 [0/1646 (0%)]\tLoss: 0.091849\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8304, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/83 [0/1646 (0%)]\tLoss: 0.107311\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9849, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/84 [0/1646 (0%)]\tLoss: 0.104093\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.6922, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 3/85 [0/1646 (0%)]\tLoss: 0.079948\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9003, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/86 [0/1646 (0%)]\tLoss: 0.101420\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           13.0540, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 3/87 [0/1646 (0%)]\tLoss: 0.084796\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7596, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 3/88 [0/1646 (0%)]\tLoss: 0.098598\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8409, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/89 [0/1646 (0%)]\tLoss: 0.095977\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9899, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/90 [0/1646 (0%)]\tLoss: 0.113994\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           13.0741, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 3/91 [0/1646 (0%)]\tLoss: 0.118849\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           13.0058, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/92 [0/1646 (0%)]\tLoss: 0.101229\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           13.0630, Accuracy: 102/1646           (6%)\n",
      "Train Fold/Epoch: 3/93 [0/1646 (0%)]\tLoss: 0.078878\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8493, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/94 [0/1646 (0%)]\tLoss: 0.095388\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8735, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/95 [0/1646 (0%)]\tLoss: 0.098568\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7742, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 3/96 [0/1646 (0%)]\tLoss: 0.093752\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9160, Accuracy: 104/1646           (6%)\n",
      "Train Fold/Epoch: 3/97 [0/1646 (0%)]\tLoss: 0.093234\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.8291, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 3/98 [0/1646 (0%)]\tLoss: 0.101434\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.9817, Accuracy: 103/1646           (6%)\n",
      "Train Fold/Epoch: 3/99 [0/1646 (0%)]\tLoss: 0.098275\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7616, Accuracy: 106/1646           (6%)\n",
      "Train Fold/Epoch: 3/100 [0/1646 (0%)]\tLoss: 0.086804\n",
      "The batch size is 64\n",
      "Test set for fold3: Average Loss:           12.7639, Accuracy: 106/1646           (6%)\n",
      "-------------------Fold 4-------------------\n",
      "Train Fold/Epoch: 4/1 [0/1646 (0%)]\tLoss: 0.108950\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9682, Accuracy: 107/1646           (7%)\n",
      "Train Fold/Epoch: 4/2 [0/1646 (0%)]\tLoss: 0.121277\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7726, Accuracy: 105/1646           (6%)\n",
      "Train Fold/Epoch: 4/3 [0/1646 (0%)]\tLoss: 0.099368\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.6136, Accuracy: 168/1646           (10%)\n",
      "Train Fold/Epoch: 4/4 [0/1646 (0%)]\tLoss: 0.087227\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8158, Accuracy: 294/1646           (18%)\n",
      "Train Fold/Epoch: 4/5 [0/1646 (0%)]\tLoss: 0.117739\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8172, Accuracy: 296/1646           (18%)\n",
      "Train Fold/Epoch: 4/6 [0/1646 (0%)]\tLoss: 0.092877\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.5961, Accuracy: 292/1646           (18%)\n",
      "Train Fold/Epoch: 4/7 [0/1646 (0%)]\tLoss: 0.092540\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7562, Accuracy: 297/1646           (18%)\n",
      "Train Fold/Epoch: 4/8 [0/1646 (0%)]\tLoss: 0.088783\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.5916, Accuracy: 299/1646           (18%)\n",
      "Train Fold/Epoch: 4/9 [0/1646 (0%)]\tLoss: 0.107686\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7414, Accuracy: 303/1646           (18%)\n",
      "Train Fold/Epoch: 4/10 [0/1646 (0%)]\tLoss: 0.090081\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7481, Accuracy: 305/1646           (19%)\n",
      "Train Fold/Epoch: 4/11 [0/1646 (0%)]\tLoss: 0.110000\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.6827, Accuracy: 304/1646           (18%)\n",
      "Train Fold/Epoch: 4/12 [0/1646 (0%)]\tLoss: 0.101856\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7474, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/13 [0/1646 (0%)]\tLoss: 0.116463\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7498, Accuracy: 305/1646           (19%)\n",
      "Train Fold/Epoch: 4/14 [0/1646 (0%)]\tLoss: 0.081222\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8455, Accuracy: 304/1646           (18%)\n",
      "Train Fold/Epoch: 4/15 [0/1646 (0%)]\tLoss: 0.112991\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8275, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/16 [0/1646 (0%)]\tLoss: 0.107614\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8289, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/17 [0/1646 (0%)]\tLoss: 0.105116\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.6070, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/18 [0/1646 (0%)]\tLoss: 0.092979\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7413, Accuracy: 310/1646           (19%)\n",
      "Train Fold/Epoch: 4/19 [0/1646 (0%)]\tLoss: 0.081785\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.6903, Accuracy: 310/1646           (19%)\n",
      "Train Fold/Epoch: 4/20 [0/1646 (0%)]\tLoss: 0.102349\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.6518, Accuracy: 310/1646           (19%)\n",
      "Train Fold/Epoch: 4/21 [0/1646 (0%)]\tLoss: 0.110061\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8439, Accuracy: 310/1646           (19%)\n",
      "Train Fold/Epoch: 4/22 [0/1646 (0%)]\tLoss: 0.078756\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9090, Accuracy: 310/1646           (19%)\n",
      "Train Fold/Epoch: 4/23 [0/1646 (0%)]\tLoss: 0.119060\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8305, Accuracy: 310/1646           (19%)\n",
      "Train Fold/Epoch: 4/24 [0/1646 (0%)]\tLoss: 0.107023\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.5491, Accuracy: 309/1646           (19%)\n",
      "Train Fold/Epoch: 4/25 [0/1646 (0%)]\tLoss: 0.102034\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8621, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/26 [0/1646 (0%)]\tLoss: 0.093466\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8075, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/27 [0/1646 (0%)]\tLoss: 0.110427\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7197, Accuracy: 312/1646           (19%)\n",
      "Train Fold/Epoch: 4/28 [0/1646 (0%)]\tLoss: 0.089847\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8903, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/29 [0/1646 (0%)]\tLoss: 0.102424\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7290, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/30 [0/1646 (0%)]\tLoss: 0.089664\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8019, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/31 [0/1646 (0%)]\tLoss: 0.081184\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7918, Accuracy: 309/1646           (19%)\n",
      "Train Fold/Epoch: 4/32 [0/1646 (0%)]\tLoss: 0.087381\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7466, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/33 [0/1646 (0%)]\tLoss: 0.112900\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7874, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/34 [0/1646 (0%)]\tLoss: 0.090401\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9419, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/35 [0/1646 (0%)]\tLoss: 0.082062\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8835, Accuracy: 305/1646           (19%)\n",
      "Train Fold/Epoch: 4/36 [0/1646 (0%)]\tLoss: 0.111041\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9325, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/37 [0/1646 (0%)]\tLoss: 0.104507\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8602, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/38 [0/1646 (0%)]\tLoss: 0.095383\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8720, Accuracy: 305/1646           (19%)\n",
      "Train Fold/Epoch: 4/39 [0/1646 (0%)]\tLoss: 0.098316\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7884, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/40 [0/1646 (0%)]\tLoss: 0.082699\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7323, Accuracy: 305/1646           (19%)\n",
      "Train Fold/Epoch: 4/41 [0/1646 (0%)]\tLoss: 0.110275\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8066, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/42 [0/1646 (0%)]\tLoss: 0.102190\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8804, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/43 [0/1646 (0%)]\tLoss: 0.095441\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8121, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/44 [0/1646 (0%)]\tLoss: 0.101571\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9769, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/45 [0/1646 (0%)]\tLoss: 0.099076\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7581, Accuracy: 305/1646           (19%)\n",
      "Train Fold/Epoch: 4/46 [0/1646 (0%)]\tLoss: 0.098261\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8082, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/47 [0/1646 (0%)]\tLoss: 0.095724\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7333, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/48 [0/1646 (0%)]\tLoss: 0.105181\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8136, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/49 [0/1646 (0%)]\tLoss: 0.107330\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           13.0069, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/50 [0/1646 (0%)]\tLoss: 0.098426\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7882, Accuracy: 310/1646           (19%)\n",
      "Train Fold/Epoch: 4/51 [0/1646 (0%)]\tLoss: 0.089908\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7570, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/52 [0/1646 (0%)]\tLoss: 0.116281\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9807, Accuracy: 305/1646           (19%)\n",
      "Train Fold/Epoch: 4/53 [0/1646 (0%)]\tLoss: 0.092590\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8417, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/54 [0/1646 (0%)]\tLoss: 0.087152\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8787, Accuracy: 309/1646           (19%)\n",
      "Train Fold/Epoch: 4/55 [0/1646 (0%)]\tLoss: 0.085157\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8301, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/56 [0/1646 (0%)]\tLoss: 0.091000\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.6720, Accuracy: 309/1646           (19%)\n",
      "Train Fold/Epoch: 4/57 [0/1646 (0%)]\tLoss: 0.113196\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8492, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/58 [0/1646 (0%)]\tLoss: 0.113380\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9959, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/59 [0/1646 (0%)]\tLoss: 0.086972\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8194, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/60 [0/1646 (0%)]\tLoss: 0.122331\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8137, Accuracy: 309/1646           (19%)\n",
      "Train Fold/Epoch: 4/61 [0/1646 (0%)]\tLoss: 0.119798\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9960, Accuracy: 309/1646           (19%)\n",
      "Train Fold/Epoch: 4/62 [0/1646 (0%)]\tLoss: 0.101274\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9752, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/63 [0/1646 (0%)]\tLoss: 0.113222\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.6908, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/64 [0/1646 (0%)]\tLoss: 0.113491\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8485, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/65 [0/1646 (0%)]\tLoss: 0.108173\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8231, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/66 [0/1646 (0%)]\tLoss: 0.087897\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9170, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/67 [0/1646 (0%)]\tLoss: 0.107127\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7039, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/68 [0/1646 (0%)]\tLoss: 0.102308\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8483, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/69 [0/1646 (0%)]\tLoss: 0.107668\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7083, Accuracy: 305/1646           (19%)\n",
      "Train Fold/Epoch: 4/70 [0/1646 (0%)]\tLoss: 0.090571\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7020, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/71 [0/1646 (0%)]\tLoss: 0.110552\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8053, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/72 [0/1646 (0%)]\tLoss: 0.095377\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9679, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/73 [0/1646 (0%)]\tLoss: 0.107064\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.6074, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/74 [0/1646 (0%)]\tLoss: 0.074016\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8229, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/75 [0/1646 (0%)]\tLoss: 0.119414\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9743, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/76 [0/1646 (0%)]\tLoss: 0.090767\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8952, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/77 [0/1646 (0%)]\tLoss: 0.090458\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7559, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/78 [0/1646 (0%)]\tLoss: 0.095438\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7682, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/79 [0/1646 (0%)]\tLoss: 0.110754\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.6775, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/80 [0/1646 (0%)]\tLoss: 0.084351\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9322, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/81 [0/1646 (0%)]\tLoss: 0.101317\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8532, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/82 [0/1646 (0%)]\tLoss: 0.118873\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           13.0797, Accuracy: 309/1646           (19%)\n",
      "Train Fold/Epoch: 4/83 [0/1646 (0%)]\tLoss: 0.098749\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7042, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/84 [0/1646 (0%)]\tLoss: 0.095918\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7835, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/85 [0/1646 (0%)]\tLoss: 0.109968\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7736, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/86 [0/1646 (0%)]\tLoss: 0.092911\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9026, Accuracy: 311/1646           (19%)\n",
      "Train Fold/Epoch: 4/87 [0/1646 (0%)]\tLoss: 0.084663\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           13.0090, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/88 [0/1646 (0%)]\tLoss: 0.104374\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7650, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/89 [0/1646 (0%)]\tLoss: 0.076720\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8319, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/90 [0/1646 (0%)]\tLoss: 0.095765\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8911, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/91 [0/1646 (0%)]\tLoss: 0.122668\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7750, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/92 [0/1646 (0%)]\tLoss: 0.107180\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7876, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/93 [0/1646 (0%)]\tLoss: 0.084605\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8560, Accuracy: 307/1646           (19%)\n",
      "Train Fold/Epoch: 4/94 [0/1646 (0%)]\tLoss: 0.116520\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8331, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/95 [0/1646 (0%)]\tLoss: 0.110132\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9322, Accuracy: 306/1646           (19%)\n",
      "Train Fold/Epoch: 4/96 [0/1646 (0%)]\tLoss: 0.087374\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9160, Accuracy: 309/1646           (19%)\n",
      "Train Fold/Epoch: 4/97 [0/1646 (0%)]\tLoss: 0.089677\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.8992, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/98 [0/1646 (0%)]\tLoss: 0.093054\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.7648, Accuracy: 308/1646           (19%)\n",
      "Train Fold/Epoch: 4/99 [0/1646 (0%)]\tLoss: 0.104921\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.9299, Accuracy: 304/1646           (18%)\n",
      "Train Fold/Epoch: 4/100 [0/1646 (0%)]\tLoss: 0.089672\n",
      "The batch size is 64\n",
      "Test set for fold4: Average Loss:           12.6734, Accuracy: 308/1646           (19%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "seq_length = 6\n",
    "folds = 5\n",
    "repeats = 12\n",
    "epochs = 100\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using {device} for training\")\n",
    "\n",
    "def reset_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "model = pMHC_TCR_model(input_size=237, hidden_size=16, batch_size=batch_size, num_layers=2, device=device, use_whole_data=False).to(device)\n",
    "kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "weights = torch.FloatTensor([5,6])\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].set_title(\"loss\")\n",
    "ax[1].set_title(\"accuracy\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(TCRData.X, TCRData.y)):\n",
    "    print(f\"-------------------Fold {fold}-------------------\")\n",
    "    if batch_size == 1:\n",
    "    # using the subsampler to get the data\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "        train_dataset = torch.utils.data.Subset(TCRData, train_idx)\n",
    "        test_dataset = torch.utils.data.Subset(TCRData, test_idx)\n",
    "        train_loader = torch.utils.data.DataLoader(TCRData, batch_size=len(train_dataset), sampler=train_subsampler)\n",
    "        test_loader = torch.utils.data.DataLoader(TCRData, batch_size=len(test_dataset), sampler=test_subsampler)\n",
    "    else:\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "        train_loader = torch.utils.data.DataLoader(TCRData, \n",
    "            batch_size=batch_size, sampler=train_subsampler, drop_last=True)\n",
    "        test_loader = torch.utils.data.DataLoader(TCRData, \n",
    "            batch_size=batch_size, sampler=test_subsampler, drop_last=True)\n",
    "    \n",
    "    # print(f\"The length of train_loader is {len(train_loader)}\") # 34\n",
    "    # print(f\"The length of test_loader is {len(test_loader)}\") # 8\n",
    "    # print(f\"The length of train_loader is {len(train_loader.dataset)}\")\n",
    "        \n",
    "    model.apply(reset_weights)\n",
    "    train_losses_history = []\n",
    "    test_losses_history = []\n",
    "    train_accuracy_history = []\n",
    "    test_accuracy_history = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_losses, train_correct = train(fold, model, device, train_loader, optimizer, epoch)\n",
    "        test_losses, test_correct = test(fold, model, device, test_loader)\n",
    "        train_losses_history.append(train_losses)\n",
    "        test_losses_history.append(test_losses)\n",
    "        train_accuracy_history.append(train_correct)\n",
    "        test_accuracy_history.append(test_correct)\n",
    "    ax[0].plot(train_losses_history, \"r*--\" ,label=f\"train loss fold{fold}\")\n",
    "    ax[0].plot(test_losses_history, \"bs--\", label=f\"test loss fold{fold}\")\n",
    "    ax[1].plot(train_accuracy_history, \"g^--\", label=f\"train accuracy fold{fold}\")\n",
    "    ax[1].plot(test_accuracy_history, \"yo--\", label=f\"test accuracy fold{fold}\")\n",
    "    # ax[0].plot(train_losses_history, label=f\"train loss fold{fold}\")\n",
    "    # ax[0].plot(test_losses_history, label=f\"test loss fold{fold}\")\n",
    "    # ax[1].plot(train_accuracy_history, label=f\"train accuracy fold{fold}\")\n",
    "    # ax[1].plot(test_accuracy_history, label=f\"test accuracy fold{fold}\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "# put the legend out of the figure, and adjust the position, prevent the figure from being covered\n",
    "# ax[0].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "# ax[1].legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "# save the figure\n",
    "fig.savefig(\"/DATA/User/wuxinchao/project/pMHC-TCR/result/pMHC_without_em_without_encoder_loss_accuracy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder model and dataset building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pMHC_TCRDataset(Dataset):\n",
    "    def __init__(self, file_path, only_TCR_seq=False, only_experimental=True):\n",
    "        # super(TCRDataset, self).__init__()\n",
    "        df = pd.read_csv(file_path, index_col=0)\n",
    "        # get the CDR3 region\n",
    "        for chain in [\"AseqCDR\", \"BseqCDR\"]:\n",
    "            # df[chain+\"_1\"] = df[chain].str.split(\"_\").str[0]\n",
    "            # df[chain+\"_2\"] = df[chain].str.split(\"_\").str[1]\n",
    "            df[chain+\"_3\"] = df[chain].str.split(\"_\").str[2]\n",
    "            df.drop(columns=[chain], inplace=True)\n",
    "\n",
    "        # generate emulated negative samples \n",
    "        if only_experimental:\n",
    "            df_ps = df[df[\"Class\"] == \"positive\"]\n",
    "            df_ng_ex = df[df[\"Class\"] == \"negative\"]\n",
    "            df_ng_em = df.copy()\n",
    "            df_ng_em = df_ng_em[df_ng_em[\"Class\"] == \"positive\"]\n",
    "            df_ng_em[\"AseqCDR_3\"] = df_ng_em[\"AseqCDR_3\"].apply(lambda x: random.choice(list(set(df_ng_em[\"AseqCDR_3\"]) - set(x))))\n",
    "            df_ng_em[\"BseqCDR_3\"] = df_ng_em[\"BseqCDR_3\"].apply(lambda x: random.choice(list(set(df_ng_em[\"BseqCDR_3\"]) - set(x))))\n",
    "            df_ng = pd.concat([df_ng_em, df_ng_ex], axis=0)\n",
    "            df_ng.index = range(len(df_ng))\n",
    "            df = pd.concat([df_ps, df_ng], axis=0)\n",
    "\n",
    "        # encode the Neo_first3, Neo_last3\n",
    "        for seq in [\"Neo_first3\", \"Neo_last3\"]:\n",
    "            df[seq] = df[seq].apply(lambda x: encode_seqCDR(x))\n",
    "        # encode the CDR3 region\n",
    "        len_map = {\n",
    "            \"AseqCDR_3\": df[\"AseqCDR_3\"].apply(lambda x: len(x)).max(),\n",
    "            \"BseqCDR_3\": df[\"BseqCDR_3\"].apply(lambda x: len(x)).max(),\n",
    "        }\n",
    "        for chain in [\"AseqCDR_3\", \"BseqCDR_3\"]:\n",
    "            length = len_map[chain]\n",
    "            df[chain] = df[chain].apply(lambda x: x + \"*\" * (length - len(x)))\n",
    "            df[chain] = df[chain].apply(lambda x: encode_seqCDR(x))\n",
    "\n",
    "        # encode HLA type through one-hot encoding\n",
    "        X_HLA = df[\"HLA\"].values.reshape(-1, 1)\n",
    "        HLAencoder = OneHotEncoder()\n",
    "        X_HLA_encoded = HLAencoder.fit_transform(X_HLA).toarray()\n",
    "\n",
    "        X_features = torch.zeros((len(df),0))\n",
    "        for seq in [\"Neo_first3\", \"Neo_last3\", \"AseqCDR_3\", \"BseqCDR_3\"]:\n",
    "            # X_features = df[seq]\n",
    "            # print(df[seq].values.shape)\n",
    "            # convert the df[seq] into torch tensor\n",
    "            X_features = torch.cat((X_features, \n",
    "            torch.from_numpy(np.vstack(df[seq].values))), dim=1)\n",
    "        \n",
    "        X = torch.cat((torch.from_numpy(X_HLA_encoded), X_features), dim=1)\n",
    "        # encode the class label\n",
    "        y = df[\"Class\"].apply(lambda x: 1 if x == \"positive\" else 0).values\n",
    "\n",
    "        if only_TCR_seq:\n",
    "            self.X = X_features\n",
    "            self.y = torch.from_numpy(y).float()\n",
    "        else:\n",
    "            self.X = X\n",
    "            self.y = torch.from_numpy(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCR_autoencoder(nn.Module):\n",
    "    '''\n",
    "    The autoencoder for TCR sequence.\n",
    "    For 230221 dataset, the sequnce length is 41 (20+21), and the input size is 41*5,\n",
    "    the hidden size is 10. And the output size is 41*5. We apply convolutional neural\n",
    "    network to encode the sequence, and apply deconvolutional neural network to decode\n",
    "    the sequence. The activation function for convolutional neural network is ReLU,\n",
    "    because it is a non-linear function, and it is easy to calculate the gradient.\n",
    "    For the decoder, we use the same activation function as the encoder.\n",
    "\n",
    "    Param:\n",
    "        input_size: the input size of the autoencoder\n",
    "        hidden_size: the hidden size of the autoencoder\n",
    "        output_size: the output size of the autoencoder, which is the same as the input size\n",
    "    '''\n",
    "    def __init__(self, kernel_size=3, stride=2, padding=1):\n",
    "        super(TCR_autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # (batch_size, 5, 47)\n",
    "            nn.Conv1d(in_channels=5, out_channels=10, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            # (batch_size, 10, 24), based on the formula for conv1d: (WF+2P)/S+1 = (47-3+2*1)/2+1 = 24\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            # (batch_size, 10, 12)\n",
    "            nn.Conv1d(in_channels=10, out_channels=20, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            # (batch_size, 20, 6), based on the formula for conv1d: (WF+2P)/S+1 = (12-3+2*1)/2+1 = 6\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            # (batch_size, 20, 3)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # (batch_size, 20, 3)\n",
    "            nn.ConvTranspose1d(in_channels=20, out_channels=10, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            # (batch_size, 10, 6), based on the formula for convtranspose1d: (W1)S2P+F = (3-1)*2-2*1+3 = 6\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            # (batch_size, 10, 12)\n",
    "            nn.ConvTranspose1d(in_channels=10, out_channels=5, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            # (batch_size, 5, 24), based on the formula for convtranspose1d: (W1)S2P+F = (12-1)*2-2*1+3 = 24\n",
    "            # nn.ReLU(),\n",
    "            # nn.Upsample(scale_factor=2),\n",
    "            # # (batch_size, 5, 47)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        print(encoded.shape)\n",
    "        output = self.decoder(encoded)\n",
    "        return encoded, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4, 12, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size per channel: (21 x 1). Calculated output size per channel: (39 x -1). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [68], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m TCR_encode_losses \u001b[39m=\u001b[39m []\n\u001b[1;32m     40\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> 41\u001b[0m     TCR_encode_loss \u001b[39m=\u001b[39m train_autoencoder(model, train_loader, optimizer, criterion, epoch)\n\u001b[1;32m     42\u001b[0m     TCR_encode_losses\u001b[39m.\u001b[39mappend(TCR_encode_loss)\n\u001b[1;32m     43\u001b[0m ax\u001b[39m.\u001b[39mplot(TCR_encode_losses, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTCR encode loss\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [68], line 9\u001b[0m, in \u001b[0;36mtrain_autoencoder\u001b[0;34m(model, train_loader, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mview(batch_size, \u001b[39m1\u001b[39m, \u001b[39m47\u001b[39m, \u001b[39m5\u001b[39m)\n\u001b[1;32m      8\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m _, output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mshape, data\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, data)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [67], line 59\u001b[0m, in \u001b[0;36mTCR_autoencoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m encoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[1;32m     58\u001b[0m \u001b[39mprint\u001b[39m(encoded\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 59\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(encoded)\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m encoded, output\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.10/site-packages/torch/nn/modules/conv.py:956\u001b[0m, in \u001b[0;36mConvTranspose2d.forward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    951\u001b[0m num_spatial_dims \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    952\u001b[0m output_padding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_padding(\n\u001b[1;32m    953\u001b[0m     \u001b[39minput\u001b[39m, output_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    954\u001b[0m     num_spatial_dims, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m--> 956\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv_transpose2d(\n\u001b[1;32m    957\u001b[0m     \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding,\n\u001b[1;32m    958\u001b[0m     output_padding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given input size per channel: (21 x 1). Calculated output size per channel: (39 x -1). Output size is too small"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training the autoencoder to encode the TCR sequence\n",
    "def train_autoencoder(model, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    TCR_encode_losses = []\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.float()\n",
    "        data = data.view(batch_size, 1, 47, 5)\n",
    "        optimizer.zero_grad()\n",
    "        _, output = model(data)\n",
    "        print(output.shape, data.shape)\n",
    "        loss = criterion(output, data)\n",
    "        TCR_encode_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "    return TCR_encode_losses / len(model.batch_size)\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "kernel_size = 3\n",
    "stride = 2\n",
    "padding = 2\n",
    "\n",
    "# train the autoencoder\n",
    "TCRData = pMHC_TCRDataset(file_path, only_TCR_seq=True, only_experimental=True)\n",
    "model = TCR_autoencoder(kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "train_loader = DataLoader(TCRData, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "# plot the loss\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "TCR_encode_losses = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    TCR_encode_loss = train_autoencoder(model, train_loader, optimizer, criterion, epoch)\n",
    "    TCR_encode_losses.append(TCR_encode_loss)\n",
    "ax.plot(TCR_encode_losses, label=\"TCR encode loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the model to encode the TCR sequence\n",
    "TCR_encoded = []\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Only Experimental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # not use \n",
    "# # The input size is 47*5, the hidden size is 10, we use two convolutional layers\n",
    "#         # to encode the sequence. The first layer: input_channel=5, output_channel=3,\n",
    "#         # kernel size is 5, stride is 2, padding is 1.\n",
    "#         # Based on the formula: (W-F+2P)/S + 1 = (47-5+2*1)/2 + 1 = 23\n",
    "#         # The second layer: input_channel=3, output_channel=1, kernel size is 5,\n",
    "#         # stride is 2, padding is 1.\n",
    "#         # Based on the formula: (W-F+2P)/S + 1 = (23-5+2*1)/2 + 1 = 11\n",
    "#         # The input shape of the encoder is (batch_size, channel, height, width=5): b, 1, 47, 5\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv2d(1, 8, kernel_size=kernel_size, stride=stride, padding=padding), \n",
    "#             # after the conv2d, the size is 24, 3\n",
    "#             nn.ReLU(True),\n",
    "#             nn.MaxPool2d(2, stride=1), \n",
    "#             # after the maxpooling, the size is 23, 2 \n",
    "#             nn.Conv2d(8, 4, kernel_size=kernel_size, stride=stride, padding=padding), \n",
    "#             # after the conv2d, the size is 12, 1\n",
    "#             nn.ReLU(True),\n",
    "#             nn.MaxPool2d(2, stride=1), \n",
    "#             # after the maxpooling, the size is 11, 1\n",
    "#         )\n",
    "#         # For the decoder, we use the same structure as the encoder. But the ConvTranspose2d is\n",
    "#         # the deconvolutional neural network. The input size is 11, the output size is 47*5.\n",
    "#         # The first layer: input_channel=1, output_channel=3, kernel size is 5,\n",
    "#         # stride is 2, padding is 1.\n",
    "#         # Based on the formula: (W-1)*S - 2P + F + O = (11-1)*2 - 2*1 + 5 + 0 = 23\n",
    "#         # The second layer: input_channel=3, output_channel=5, kernel size is 5,\n",
    "#         # stride is 2, padding is 1.\n",
    "#         # Based on the formula: (W-1)*S - 2P + F + O = (23-1)*2 - 2*1 + 5 + 0 = 47\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(4, 8, kernel_size=kernel_size, stride=stride, padding=padding), \n",
    "#             # after the convtranspose2d, the size is 23, 4\n",
    "#             nn.ReLU(True),\n",
    "#             nn.ConvTranspose2d(8, 1, kernel_size=kernel_size, stride=stride, padding=padding), \n",
    "#             # after the convtranspose2d, the size is 47, 5\n",
    "#             nn.ReLU(True),\n",
    "#         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9a3d897ef0b1e7415fe4468808571913e41281b79a56511723d411ccb064e7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
